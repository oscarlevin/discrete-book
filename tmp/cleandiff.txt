diff normal/backmatter.mbx clean/backmatter.mbx
20c20
< <index-part>
---
> <index>
23c23
< </index-part>
---
> </index>
diff normal/ch_graphtheory.mbx clean/ch_graphtheory.mbx
11c11
<       <figure>
---
>       <sidebyside>
13c13
<           <latex-image-code>
---
>           <latex-image>
46c46
<           </latex-image-code>
---
>           </latex-image>
48c48
<       </figure>
---
>       </sidebyside>
55c55
<       The problem above, known as the <em>Seven Bridges of Königsberg</em><index><main>Königsberg</main></index>, is the problem that originally inspired graph theory. Consider a <q>different</q> problem: Below is a drawing of four dots connected by some lines. Is it possible to trace over each line once and only once (without lifting up your pencil, starting and ending on a dot)?
---
>       The problem above, known as the <em>Seven Bridges of Königsberg</em><idx><h>Königsberg</h></idx>, is the problem that originally inspired graph theory. Consider a <q>different</q> problem: Below is a drawing of four dots connected by some lines. Is it possible to trace over each line once and only once (without lifting up your pencil, starting and ending on a dot)?
60,62c60,62
<       <figure>
<         <image xml:id="gt-bridges-graph" width="25%">
<           <latex-image-code>
---
>       <sidebyside width="25%">
>         <image xml:id="gt-bridges-graph">
>           <latex-image>
67c67
<           </latex-image-code>
---
>           </latex-image>
69c69
<       </figure>
---
>       </sidebyside>
78c78
<       Pictures like the dot and line drawing are called <term>graphs</term>. Graphs are made up of a collection of dots called <term>vertices</term><index><main>vertices</main></index> and lines connecting those dots called <term>edges</term><index><main>edges</main></index>. When two vertices are connected by an edge, we say they are <term>adjacent</term><index><main>adjacent</main></index>. The nice thing about looking at graphs instead of pictures of rivers, islands and bridges is that we now have a mathematical object to study. We have distilled the <q>important</q> parts of the bridge picture for the purposes of the problem. It does not matter how big the islands are, what the bridges are made out of, if the river contains alligators, etc. All that matters is which land masses are connected to which other land masses, and how many times.
---
>       Pictures like the dot and line drawing are called <term>graphs</term>. Graphs are made up of a collection of dots called <term>vertices</term><idx><h>vertices</h></idx> and lines connecting those dots called <term>edges</term><idx><h>edges</h></idx>. When two vertices are connected by an edge, we say they are <term>adjacent</term><idx><h>adjacent</h></idx>. The nice thing about looking at graphs instead of pictures of rivers, islands and bridges is that we now have a mathematical object to study. We have distilled the <q>important</q> parts of the bridge picture for the purposes of the problem. It does not matter how big the islands are, what the bridges are made out of, if the river contains alligators, etc. All that matters is which land masses are connected to which other land masses, and how many times.
95,97c95,97
<         <figure>
<           <image xml:id="gt-facebook" width="20%">
<             <latex-image-code>
---
>         <sidebyside width="20%">
>           <image xml:id="gt-facebook">
>             <latex-image>
101c101
<             </latex-image-code>
---
>             </latex-image>
103c103
<         </figure>
---
>         </sidebyside>
118,120c118,120
<         <figure>
<           <image xml:id="gt-k33" width="20%">
<             <latex-image-code>
---
>         <sidebyside width="20%">
>           <image xml:id="gt-k33">
>             <latex-image>
124c124
<             </latex-image-code>
---
>             </latex-image>
126c126
<         </figure>
---
>         </sidebyside>
diff normal/ch_logic.mbx clean/ch_logic.mbx
21c21
<         An <term>argument</term><index><main>argument</main></index> is a set of statements, one of which is called the <term>conclusion</term><index><main>conclusion</main></index> and the rest of which are called <term>premises</term><index><main>premises</main></index>. An argument is said to be <term>valid</term><index><main>valid</main></index> if the conclusion must be true whenever the premises are all true. An argument is <term>invalid</term> if it is not valid; it is possible for all the premises to be true and the conclusion to be false.
---
>         An <term>argument</term><idx><h>argument</h></idx> is a set of statements, one of which is called the <term>conclusion</term><idx><h>conclusion</h></idx> and the rest of which are called <term>premises</term><idx><h>premises</h></idx>. An argument is said to be <term>valid</term><idx><h>valid</h></idx> if the conclusion must be true whenever the premises are all true. An argument is <term>invalid</term> if it is not valid; it is possible for all the premises to be true and the conclusion to be false.
28c28
<     <table>
---
>     <sidebyside>
43,44c43,44
<     </table>
<     <table>
---
>     </sidebyside>
>     <sidebyside>
59c59
<     </table>
---
>     </sidebyside>
diff normal/ch_sequences.mbx clean/ch_sequences.mbx
9c9
<       There is a monastery in Hanoi<index><main>Hanoi</main></index>, as the legend goes, with a great hall containing three tall pillars. Resting on the first pillar are 64 giant disks (or washers), all different sizes, stacked from largest to smallest. The monks are charged with the following task: they must move the entire stack of disks to the third pillar. However, due to the size of the disks, the monks cannot move more than one at a time. Each disk must be placed on one of the pillars before the next disk is moved. And because the disks are so heavy and fragile, the monks may never place a larger disk on top of a smaller disk. When the monks finally complete their task, the world shall come to an end. Your task: figure out how long before we need to start worrying about the end of the world.
---
>       There is a monastery in Hanoi<idx><h>Hanoi</h></idx>, as the legend goes, with a great hall containing three tall pillars. Resting on the first pillar are 64 giant disks (or washers), all different sizes, stacked from largest to smallest. The monks are charged with the following task: they must move the entire stack of disks to the third pillar. However, due to the size of the disks, the monks cannot move more than one at a time. Each disk must be placed on one of the pillars before the next disk is moved. And because the disks are so heavy and fragile, the monks may never place a larger disk on top of a smaller disk. When the monks finally complete their task, the world shall come to an end. Your task: figure out how long before we need to start worrying about the end of the world.
27c27
<       This puzzle is called the <em>Tower of Hanoi</em><index><main>Tower of Hanoi</main></index>. You are tasked with finding the minimum number of moves to complete the puzzle. This certainly sounds like a counting problem. Perhaps you have an answer? If not, what else could we try?
---
>       This puzzle is called the <em>Tower of Hanoi</em><idx><h>Tower of Hanoi</h></idx>. You are tasked with finding the minimum number of moves to complete the puzzle. This certainly sounds like a counting problem. Perhaps you have an answer? If not, what else could we try?
Common subdirectories: normal/exercises and clean/exercises
diff normal/sec_addtops-numbth.mbx clean/sec_addtops-numbth.mbx
46c46
< If given numbers <m>a</m> and <m>b</m>, it is possible that <m>a \div b</m> gives a whole number. In this case, we say that <m>b</m> <em>divides</em><index><main>divides</main></index> <m>a</m>, in symbols, we write <m>b \mid a</m>. If this holds, then <m>b</m> is a divisor or factor of <m>a</m>, and <m>a</m> is a multiple of <m>b</m>. In other words, if <m>b \mid a</m>, then <m>a = bk</m> for some integer <m>k</m> (this is saying <m>a</m> is some multiple of <m>b</m>).
---
> If given numbers <m>a</m> and <m>b</m>, it is possible that <m>a \div b</m> gives a whole number. In this case, we say that <m>b</m> <em>divides</em><idx><h>divides</h></idx> <m>a</m>, in symbols, we write <m>b \mid a</m>. If this holds, then <m>b</m> is a divisor or factor of <m>a</m>, and <m>a</m> is a multiple of <m>b</m>. In other words, if <m>b \mid a</m>, then <m>a = bk</m> for some integer <m>k</m> (this is saying <m>a</m> is some multiple of <m>b</m>).
51c51
< <index><main>divisibility relation</main></index>
---
> <idx><h>divisibility relation</h></idx>
185c185
< <index><main>Division algorithm</main></index>
---
> <idx><h>Division algorithm</h></idx>
264c264
< which is read, <q>8 is congruent to 23 modulo 5</q> (or just <q>mod 5</q>).<index><main>mod</main></index> Of course then we could observe that
---
> which is read, <q>8 is congruent to 23 modulo 5</q> (or just <q>mod 5</q>).<idx><h>mod</h></idx> Of course then we could observe that
272c272
< We say <term><m>a</m> is congruent to <m>b</m> modulo <m>n</m></term><index><main>congruence</main></index><index><main>modulo <m>n</m></main></index>, and write,
---
> We say <term><m>a</m> is congruent to <m>b</m> modulo <m>n</m></term><idx><h>congruence</h></idx><idx><h>modulo <m>n</m></h></idx>, and write,
373c373
< <index><main>modular arithmetic</main></index>
---
> <idx><h>modular arithmetic</h></idx>
516c516
< We will call the largest factor of both <m>d</m> and <m>n</m> the <m>\gcd(d,n)</m>, for <em>greatest common divisor</em><index><main>gcd</main></index><index><main>greatest commond divisor</main></index>. In our example above, <m>\gcd(6,8) = 2</m> since the greatest divisor common to 6 and 8 is 2.
---
> We will call the largest factor of both <m>d</m> and <m>n</m> the <m>\gcd(d,n)</m>, for <em>greatest common divisor</em><idx><h>gcd</h></idx><idx><h>greatest commond divisor</h></idx>. In our example above, <m>\gcd(6,8) = 2</m> since the greatest divisor common to 6 and 8 is 2.
704c704
< Discrete math deals with whole numbers of things. So when we want to solve equations, we usually are looking for <em>integer</em> solutions. Equations which are intended to only have integer solutions were first studied by in the third century by the Greek mathematician Diophantus of Alexandria, and as such are called <em>Diophantine equations</em><index><main>Diophantine equation</main></index>. Probably the most famous example of a Diophantine equation is <m>a^2 + b^2 = c^2</m>. The integer solutions to this equation are called <em>Pythagorean triples</em>. In general, solving Diophantine equations is hard (in fact, there is provably no general algorithm for deciding whether a Diophantine equation has a solution, a result known as Matiyasevich's Theorem). We will restrict our focus to <em>linear</em> Diophantine equations, which are considerably easier to work with.
---
> Discrete math deals with whole numbers of things. So when we want to solve equations, we usually are looking for <em>integer</em> solutions. Equations which are intended to only have integer solutions were first studied by in the third century by the Greek mathematician Diophantus of Alexandria, and as such are called <em>Diophantine equations</em><idx><h>Diophantine equation</h></idx>. Probably the most famous example of a Diophantine equation is <m>a^2 + b^2 = c^2</m>. The integer solutions to this equation are called <em>Pythagorean triples</em>. In general, solving Diophantine equations is hard (in fact, there is provably no general algorithm for deciding whether a Diophantine equation has a solution, a result known as Matiyasevich's Theorem). We will restrict our focus to <em>linear</em> Diophantine equations, which are considerably easier to work with.
843c843
< <table>
---
> <sidebyside>
854c854
< </table>
---
> </sidebyside>
diff normal/sec_counting-addmult.mbx clean/sec_counting-addmult.mbx
51c51
<       <term>additive principle</term><index><main>additive principle</main></index> states that if event <m>A</m> can occur in <m>m</m> ways, and event <m>B</m> can occur in <m>n</m>
---
>       <term>additive principle</term><idx><h>additive principle</h></idx> states that if event <m>A</m> can occur in <m>m</m> ways, and event <m>B</m> can occur in <m>n</m>
56c56
<     It is important that the events be <term>disjoint</term>: i.e., that there is no way for <m>A</m> and <m>B</m> to both happen at the same time.<index><main>disjoint</main></index> For example, a standard deck of 52 cards contains <m>26</m> red cards and <m>12</m> face cards. However, the number of ways to select a card which is either red or a face card is not <m>26 + 12 = 38</m>. This is because there are 6 cards which are both red and face cards.
---
>     It is important that the events be <term>disjoint</term>: i.e., that there is no way for <m>A</m> and <m>B</m> to both happen at the same time.<idx><h>disjoint</h></idx> For example, a standard deck of 52 cards contains <m>26</m> red cards and <m>12</m> face cards. However, the number of ways to select a card which is either red or a face card is not <m>26 + 12 = 38</m>. This is because there are 6 cards which are both red and face cards.
62c62
<         How many two letter <q>words</q><index><main>word</main></index> start with either A or B? (A <term>word</term> is just a string of letters; it doesn't have to be English, or even pronounceable.)
---
>         How many two letter <q>words</q><idx><h>word</h></idx> start with either A or B? (A <term>word</term> is just a string of letters; it doesn't have to be English, or even pronounceable.)
110c110
<       <term>multiplicative principle</term><index><main>multiplicative principle</main></index> states that if event <m>A</m> can occur in <m>m</m> ways, and each possibility for <m>A</m> allows for exactly <m>n</m> ways for event <m>B</m>, then the event <q><m>A</m> and <m>B</m></q> can occur in <m>m \cdot n</m> ways.
---
>       <term>multiplicative principle</term><idx><h>multiplicative principle</h></idx> states that if event <m>A</m> can occur in <m>m</m> ways, and each possibility for <m>A</m> allows for exactly <m>n</m> ways for event <m>B</m>, then the event <q><m>A</m> and <m>B</m></q> can occur in <m>m \cdot n</m> ways.
226c226
<         <index><main>additive principle</main></index> Given two sets <m>A</m> and <m>B</m>, if <m>A \cap B = \emptyset</m> (that is, if there is no element in common to both <m>A</m> and <m>B</m>), then
---
>         <idx><h>additive principle</h></idx> Given two sets <m>A</m> and <m>B</m>, if <m>A \cap B = \emptyset</m> (that is, if there is no element in common to both <m>A</m> and <m>B</m>), then
244c244
<         <term>Cartesian product</term><index><main>Cartesian product</main></index> of <m>A</m> and <m>B</m>.
---
>         <term>Cartesian product</term><idx><h>Cartesian product</h></idx> of <m>A</m> and <m>B</m>.
300c300
<         <index><main>multiplicative principle</main></index> Given two sets <m>A</m> and <m>B</m>, we have <m>\card{A \times B} = \card{A} \cdot \card{B}</m>.
---
>         <idx><h>multiplicative principle</h></idx> Given two sets <m>A</m> and <m>B</m>, we have <m>\card{A \times B} = \card{A} \cdot \card{B}</m>.
315c315
<       <table>
---
>       <sidebyside>
338c338
<       </table>
---
>       </sidebyside>
347c347
<       <index><main>principle of inclusion/exclusion</main></index><index><main>PIE</main></index> While we are thinking about sets, consider what happens to the additive principle when the sets are NOT disjoint. Suppose we want to find <m>\card{A \cup B}</m> and know that <m>\card{A} = 10</m> and <m>\card{B} = 8</m>. This is not enough information though. We do not know how many of the 8 elements in <m>B</m> are also elements of <m>A</m>. However, if we also know that <m>\card{A \cap B} = 6</m>, then we can say exactly how many elements are in <m>A</m>, and, of those, how many are in <m>B</m> and how many are not (6 of the 10 elements are in <m>B</m>, so 4 are in <m>A</m> but not in <m>B</m>). We could fill in a Venn diagram <index><main>Venn diagram</main></index> as follows:
---
>       <idx><h>principle of inclusion/exclusion</h></idx><idx><h>PIE</h></idx> While we are thinking about sets, consider what happens to the additive principle when the sets are NOT disjoint. Suppose we want to find <m>\card{A \cup B}</m> and know that <m>\card{A} = 10</m> and <m>\card{B} = 8</m>. This is not enough information though. We do not know how many of the 8 elements in <m>B</m> are also elements of <m>A</m>. However, if we also know that <m>\card{A \cap B} = 6</m>, then we can say exactly how many elements are in <m>A</m>, and, of those, how many are in <m>B</m> and how many are not (6 of the 10 elements are in <m>B</m>, so 4 are in <m>A</m> but not in <m>B</m>). We could fill in a Venn diagram <idx><h>Venn diagram</h></idx> as follows:
349,351c349,351
<     <figure>
<       <image width="40%">
<         <latex-image-code>
---
>     <sidebyside width="40%">
>       <image>
>         <latex-image>
356c356
<         </latex-image-code>
---
>         </latex-image>
358c358
<     </figure>
---
>     </sidebyside>
399c399
<         <table>
---
>         <sidebyside>
423c423
<         </table>
---
>         </sidebyside>
432,434c432,434
<         <figure>
<           <image width="36%">
<             <latex-image-code>
---
>         <sidebyside width="36%">
>           <image>
>             <latex-image>
439c439
<             </latex-image-code>
---
>             </latex-image>
441c441
<         </figure>
---
>         </sidebyside>
445,447c445,447
<         <figure>
<           <image width="36%">
<             <latex-image-code>
---
>         <sidebyside width="36%">
>           <image>
>             <latex-image>
452c452
<             </latex-image-code>
---
>             </latex-image>
454c454
<         </figure>
---
>         </sidebyside>
458,460c458,460
<         <figure>
<           <image width="36%">
<             <latex-image-code>
---
>         <sidebyside width="36%">
>           <image>
>             <latex-image>
466c466
<             </latex-image-code>
---
>             </latex-image>
468c468
<         </figure>
---
>         </sidebyside>
diff normal/sec_counting-advPIE.mbx clean/sec_counting-advPIE.mbx
216c216
<       The advanced use of PIE has applications beyond stars and bars. A <term>derangement</term><index><main>derangement</main></index> of <m>n</m> elements <m>\{1,2,3,\ldots, n\}</m> is a permutation in which no element is fixed. For example, there are <m>6</m> permutations of the three elements <m>\{1,2,3\}</m>:
---
>       The advanced use of PIE has applications beyond stars and bars. A <term>derangement</term><idx><h>derangement</h></idx> of <m>n</m> elements <m>\{1,2,3,\ldots, n\}</m> is a permutation in which no element is fixed. For example, there are <m>6</m> permutations of the three elements <m>\{1,2,3\}</m>:
diff normal/sec_counting-binom.mbx clean/sec_counting-binom.mbx
14,16c14,16
<     <figure>
<       <image xml:id="chessboard" width="50%">
<         <latex-image-code>
---
>     <sidebyside width="50%">
>       <image xml:id="chessboard">
>         <latex-image>
29c29
<         </latex-image-code>
---
>         </latex-image>
32c32
<     </figure>
---
>     </sidebyside>
70c70
<       <table>
---
>       <sidebyside>
92c92
<       </table>
---
>       </sidebyside>
116c116
<           <index><main>bit string</main></index>
---
>           <idx><h>bit string</h></idx>
125c125
< The <term>weight</term><index><main>weight, of a string</main></index> of a bit string is the number of 1's in it.
---
> The <term>weight</term><idx><h>weight, of a string</h></idx> of a bit string is the number of 1's in it.
186c186
<         A <term>lattice path</term><index><main>lattice path</main></index> is one of the shortest possible paths connecting two points on the lattice, moving only horizontally and vertically. For example, here are three possible lattice paths from the points <m>(0,0)</m> to <m>(3,2)</m>:
---
>         A <term>lattice path</term><idx><h>lattice path</h></idx> is one of the shortest possible paths connecting two points on the lattice, moving only horizontally and vertically. For example, here are three possible lattice paths from the points <m>(0,0)</m> to <m>(3,2)</m>:
190c190
<           <latex-image-code>
---
>           <latex-image>
199c199
<           </latex-image-code>
---
>           </latex-image>
202c202
<           <latex-image-code>
---
>           <latex-image>
211c211
<           </latex-image-code>
---
>           </latex-image>
214c214
<           <latex-image-code>
---
>           <latex-image>
223c223
<           </latex-image-code>
---
>           </latex-image>
241,243c241,243
<       <figure>
<         <image xml:id="lattice-ab" width="40%">
<           <latex-image-code>
---
>       <sidebyside width="40%">
>         <image xml:id="lattice-ab">
>           <latex-image>
252c252
<           </latex-image-code>
---
>           </latex-image>
254c254
<       </figure>
---
>       </sidebyside>
309c309
<           <index><main>binomial coefficients</main></index> For each integer <m>n \ge 0</m> and integer <m>k</m> with <m>0 \le k \le n</m> there is a number
---
>           <idx><h>binomial coefficients</h></idx> For each integer <m>n \ge 0</m> and integer <m>k</m> with <m>0 \le k \le n</m> there is a number
382,384c382,384
<       <figure>
<         <image xml:id="pascal-nCk" width="70%">
<           <latex-image-code>
---
>       <sidebyside width="70%">
>         <image xml:id="pascal-nCk">
>           <latex-image>
390c390
<           </latex-image-code>
---
>           </latex-image>
392c392
<       </figure>
---
>       </sidebyside>
403c403
<       <index><main>Pascal's triangle</main></index>
---
>       <idx><h>Pascal's triangle</h></idx>
406c406
<         <figure>
---
>         
408c408
<             <latex-image-code>
---
>             <latex-image>
437c437
<             </latex-image-code>
---
>             </latex-image>
439c439
<         </figure>
---
>         
diff normal/sec_counting-combperm.mbx clean/sec_counting-combperm.mbx
63c63
<   <p> A piece of notation is helpful here: <m>n!</m>, read <q><m>n</m> factorial</q>,<index><main>factorial</main></index> is the product of all positive integers less than or equal to <m>n</m> (for reasons of convenience, we also define 0! to be 1). So the number of permutation of 6 letters, as seen in the previous example is <m>6! = 6\cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1</m>. This generalizes:</p>
---
>   <p> A piece of notation is helpful here: <m>n!</m>, read <q><m>n</m> factorial</q>,<idx><h>factorial</h></idx> is the product of all positive integers less than or equal to <m>n</m> (for reasons of convenience, we also define 0! to be 1). So the number of permutation of 6 letters, as seen in the previous example is <m>6! = 6\cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1</m>. This generalizes:</p>
133c133
<           <index><main><em>k</em>-permutation</main></index><index><main>permutation</main></index>
---
>           <idx><h><em>k</em>-permutation</h></idx><idx><h>permutation</h></idx>
195c195
<           We say <m>P(n,k)</m> counts <em>permutations</em>, and <m>{n \choose k}</m> counts <em>combinations</em><index><main>combination</main></index>. The formulas for each are very similar, there is just an extra <m>k!</m> in the denominator of <m>{n \choose k}</m>. That extra <m>k!</m> accounts for the fact that <m>{n \choose k}</m> does not distinguish between the different orders that the <m>k</m> objects can appear in. We are just selecting (or choosing) the <m>k</m> objects, not arranging them. Perhaps <q>combination</q> is a misleading label. We don't mean it like a combination lock (where the order would definitely matter). Perhaps a better metaphor is a combination of flavors
---
>           We say <m>P(n,k)</m> counts <em>permutations</em>, and <m>{n \choose k}</m> counts <em>combinations</em><idx><h>combination</h></idx>. The formulas for each are very similar, there is just an extra <m>k!</m> in the denominator of <m>{n \choose k}</m>. That extra <m>k!</m> accounts for the fact that <m>{n \choose k}</m> does not distinguish between the different orders that the <m>k</m> objects can appear in. We are just selecting (or choosing) the <m>k</m> objects, not arranging them. Perhaps <q>combination</q> is a misleading label. We don't mean it like a combination lock (where the order would definitely matter). Perhaps a better metaphor is a combination of flavors
diff normal/sec_counting-conc.mbx clean/sec_counting-conc.mbx
10c10
<         <table>
---
>         <sidebyside>
19c19
<     </table>
---
>     </sidebyside>
diff normal/sec_counting-proofs.mbx clean/sec_counting-proofs.mbx
53,55c53,55
<     <figure>
<       <image xml:id="pascal-small" width="80%">
<         <latex-image-code>
---
>     <sidebyside width="80%">
>       <image xml:id="pascal-small">
>         <latex-image>
86c86
<         </latex-image-code>
---
>         </latex-image>
88c88
<     </figure>
---
>     </sidebyside>
135c135
<       Each of these is an example of a <term>binomial identity</term><index><main>binomial identity</main></index>: an identity (i.e., equation) involving binomial coefficients.
---
>       Each of these is an example of a <term>binomial identity</term><idx><h>binomial identity</h></idx>: an identity (i.e., equation) involving binomial coefficients.
528,530c528,530
<           <figure>
<             <image xml:id="lattice-paths-comb-proof" width="40%">
<               <latex-image-code>
---
>           <sidebyside width="40%">
>             <image xml:id="lattice-paths-comb-proof">
>               <latex-image>
537c537
<               </latex-image-code>
---
>               </latex-image>
539c539
<           </figure>
---
>           </sidebyside>
diff normal/sec_counting-starsbars.mbx clean/sec_counting-starsbars.mbx
5,7c5,7
<         <index>
<             <main>stars and bars</main>
<         </index>
---
>         <idx>
>             <h>stars and bars</h>
>         </idx>
diff normal/sec_gt-coloring.mbx clean/sec_gt-coloring.mbx
11,13c11,13
< <figure>
< 	<image width="75%">
< 	<latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="75%">
> 	<image>
> 	<latex-image>\begin{tikzpicture}
27c27
< 	\end{tikzpicture}</latex-image-code>
---
> 	\end{tikzpicture}</latex-image>
29c29
< </figure>
---
> </sidebyside>
47c47
< In general, given any graph <m>G</m>, a coloring of the vertices is called (not surprisingly) a <em>vertex coloring</em><index><main>vertex coloring</main></index><index><main>coloring</main></index>. If the vertex coloring has the property that adjacent vertices are colored differently, then the coloring is called <em>proper</em>. Every graph has a proper vertex coloring. For example, you could color every vertex with a different color. But often you can do better. The smallest number of colors needed to get a proper vertex coloring is called the <em>chromatic number</em><index><main>chromatic number</main></index> of the graph, written <m>\chi(G)</m><notation><usage>\chi(G)</usage><description>the chromatic number of <m>G</m></description></notation>.
---
> In general, given any graph <m>G</m>, a coloring of the vertices is called (not surprisingly) a <em>vertex coloring</em><idx><h>vertex coloring</h></idx><idx><h>coloring</h></idx>. If the vertex coloring has the property that adjacent vertices are colored differently, then the coloring is called <em>proper</em>. Every graph has a proper vertex coloring. For example, you could color every vertex with a different color. But often you can do better. The smallest number of colors needed to get a proper vertex coloring is called the <em>chromatic number</em><idx><h>chromatic number</h></idx> of the graph, written <m>\chi(G)</m><notation><usage>\chi(G)</usage><description>the chromatic number of <m>G</m></description></notation>.
57c57
< 	<latex-image-code>\begin{tikzpicture}
---
> 	<latex-image>\begin{tikzpicture}
60c60
< 	    \end{tikzpicture}</latex-image-code>
---
> 	    \end{tikzpicture}</latex-image>
63c63
< 	<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> 	<latex-image>\begin{tikzpicture}[yscale=.8]
65c65
< 	    \end{tikzpicture}</latex-image-code>
---
> 	    \end{tikzpicture}</latex-image>
68c68
< 	<latex-image-code>\begin{tikzpicture}[yscale=.8, xscale=1.5]
---
> 	<latex-image>\begin{tikzpicture}[yscale=.8, xscale=1.5]
70c70
< 	  \end{tikzpicture}</latex-image-code>
---
> 	  \end{tikzpicture}</latex-image>
83,85c83,85
< <figure>
< 	<image width="25%">
< 	<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> <sidebyside width="25%">
> 	<image>
> 	<latex-image>\begin{tikzpicture}[yscale=.8]
87c87
< 	    \end{tikzpicture}</latex-image-code>
---
> 	    \end{tikzpicture}</latex-image>
89c89
< </figure>
---
> </sidebyside>
115c115
< <index><main>Four Color Theorem</main></index>
---
> <idx><h>Four Color Theorem</h></idx>
133c133
< <table>
---
> <sidebyside>
148c148
< </table>
---
> </sidebyside>
194c194
< 	<latex-image-code>
---
> 	<latex-image>
209c209
< 	</latex-image-code>
---
> 	</latex-image>
226c226
< 	<latex-image-code>\begin{tikzpicture}[scale=.9]
---
> 	<latex-image>\begin{tikzpicture}[scale=.9]
241c241
< 	\end{tikzpicture}</latex-image-code>
---
> 	\end{tikzpicture}</latex-image>
244c244
< 	<latex-image-code>\begin{tikzpicture}[scale=.9]
---
> 	<latex-image>\begin{tikzpicture}[scale=.9]
260c260
< 	\end{tikzpicture}</latex-image-code>
---
> 	\end{tikzpicture}</latex-image>
282c282
< A <term>clique</term><index><main>clique</main></index> in a graph is a set of vertices all of which are pairwise adjacent. In other words, a clique of size <m>n</m> is just a copy of the complete graph <m>K_n</m>. We define the <term>clique number</term> of a graph to be the largest <m>n</m> for which the graph contains a clique of size <m>n</m>. Any clique of size <m>n</m> cannot be colored with fewer than <m>n</m> colors, so we have a nice lower bound:
---
> A <term>clique</term><idx><h>clique</h></idx> in a graph is a set of vertices all of which are pairwise adjacent. In other words, a clique of size <m>n</m> is just a copy of the complete graph <m>K_n</m>. We define the <term>clique number</term> of a graph to be the largest <m>n</m> for which the graph contains a clique of size <m>n</m>. Any clique of size <m>n</m> cannot be colored with fewer than <m>n</m> colors, so we have a nice lower bound:
294c294
< There are times when the chromatic number of <m>G</m> is <em>equal</em> to the clique number. These graphs have a special name; they are called <term>perfect</term><index><main>perfect graph</main></index>. If you know that a graph is perfect, then finding the chromatic number is simply a matter of searching for the largest clique.<fn>There are special classes of graphs which can be proved to be perfect.  One such class is the set of <term>chordal</term> graphs, which have the property that every cycle in the graph contains a <term>chord</term><mdash/>an edge between two vertices in of the cycle which are not adjacent in the cycle.</fn> However, not all graphs are perfect.
---
> There are times when the chromatic number of <m>G</m> is <em>equal</em> to the clique number. These graphs have a special name; they are called <term>perfect</term><idx><h>perfect graph</h></idx>. If you know that a graph is perfect, then finding the chromatic number is simply a matter of searching for the largest clique.<fn>There are special classes of graphs which can be proved to be perfect.  One such class is the set of <term>chordal</term> graphs, which have the property that every cycle in the graph contains a <term>chord</term><mdash/>an edge between two vertices in of the cycle which are not adjacent in the cycle.</fn> However, not all graphs are perfect.
309c309
< <index><main>Brooks' Theorem</main></index>
---
> <idx><h>Brooks' Theorem</h></idx>
324c324
< The chromatic number of a graph tells us about coloring vertices, but we could also ask about coloring edges. Just like with vertex coloring, we might insist that edges that are adjacent must be colored differently. Here, we are thinking of two edges as being adjacent if they are incident to the same vertex. The least number of colors required to properly color the edges of a graph <m>G</m> is called the <term>chromatic index</term><index><main>chromatic index</main></index> of <m>G</m>, written <m>\chi'(G)</m><notation><usage>\chi'(G)</usage><description>the chromatic index of <m>G</m></description></notation>.
---
> The chromatic number of a graph tells us about coloring vertices, but we could also ask about coloring edges. Just like with vertex coloring, we might insist that edges that are adjacent must be colored differently. Here, we are thinking of two edges as being adjacent if they are incident to the same vertex. The least number of colors required to properly color the edges of a graph <m>G</m> is called the <term>chromatic index</term><idx><h>chromatic index</h></idx> of <m>G</m>, written <m>\chi'(G)</m><notation><usage>\chi'(G)</usage><description>the chromatic index of <m>G</m></description></notation>.
336,338c336,338
< <figure>
< 	<image width="20%">
< 	<latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="20%">
> 	<image>
> 	<latex-image>\begin{tikzpicture}
346c346
< 	\end{tikzpicture}</latex-image-code>
---
> 	\end{tikzpicture}</latex-image>
348c348
< </figure>
---
> </sidebyside>
370c370
< <index><main>Vizing's Theorem</main></index>
---
> <idx><h>Vizing's Theorem</h></idx>
381c381
< There is another interesting way we might consider coloring edges, quite different from what we have discussed so far. What if we colored every edge of a graph either red or blue. Can we do so without, say, creating a <em>monochromatic</em><index><main>monochromatic</main></index> triangle (i.e., an all red or all blue triangle)? Certainly for some graphs the answer is yes. Try doing so for <m>K_4</m>. What about <m>K_5</m>? <m>K_6</m>? How far can we go?
---
> There is another interesting way we might consider coloring edges, quite different from what we have discussed so far. What if we colored every edge of a graph either red or blue. Can we do so without, say, creating a <em>monochromatic</em><idx><h>monochromatic</h></idx> triangle (i.e., an all red or all blue triangle)? Certainly for some graphs the answer is yes. Try doing so for <m>K_4</m>. What about <m>K_5</m>? <m>K_6</m>? How far can we go?
385c385
< The answer to the above problem is known and is a fun problem to do as an exercise. We could extend the question in a variety of ways. What if we had three colors? What if we were trying to avoid other graphs. The surprising fact is that very little is known about these questions. For example, we know that you need to go up to <m>K_{17}</m> in order to force a monochromatic triangle using three colors, but nobody knows how big you need to go with more colors. Similarly, we know that using two colors <m>K_{18}</m> is the smallest graph that forces a monochromatic copy of <m>K_4</m>, but the best we have to force a monochromatic <m>K_{5}</m> is a range, somewhere from <m>K_{43}</m> to <m>K_{49}</m>. If you are interested in these sorts of questions, this area of graph theory is called Ramsey theory<index><main>Ramsey theory</main></index>. Check it out.
---
> The answer to the above problem is known and is a fun problem to do as an exercise. We could extend the question in a variety of ways. What if we had three colors? What if we were trying to avoid other graphs. The surprising fact is that very little is known about these questions. For example, we know that you need to go up to <m>K_{17}</m> in order to force a monochromatic triangle using three colors, but nobody knows how big you need to go with more colors. Similarly, we know that using two colors <m>K_{18}</m> is the smallest graph that forces a monochromatic copy of <m>K_4</m>, but the best we have to force a monochromatic <m>K_{5}</m> is a range, somewhere from <m>K_{43}</m> to <m>K_{49}</m>. If you are interested in these sorts of questions, this area of graph theory is called Ramsey theory<idx><h>Ramsey theory</h></idx>. Check it out.
diff normal/sec_gt-intro.mbx clean/sec_gt-intro.mbx
13c13
< 				<latex-image-code>
---
> 				<latex-image>
28c28
< 				</latex-image-code>
---
> 				</latex-image>
31c31
< 				<latex-image-code>
---
> 				<latex-image>
46c46
< 				</latex-image-code>
---
> 				</latex-image>
49c49
< 				<latex-image-code>
---
> 				<latex-image>
64c64
< 				</latex-image-code>
---
> 				</latex-image>
67c67
< 				<latex-image-code>
---
> 				<latex-image>
82c82
< 				</latex-image-code>
---
> 				</latex-image>
85c85
< 				<latex-image-code>
---
> 				<latex-image>
100c100
< 				</latex-image-code>
---
> 				</latex-image>
106c106
< 				<latex-image-code>
---
> 				<latex-image>
122c122
< 				</latex-image-code>
---
> 				</latex-image>
125c125
< 				<latex-image-code>
---
> 				<latex-image>
141c141
< 				</latex-image-code>
---
> 				</latex-image>
144c144
< 				<latex-image-code>
---
> 				<latex-image>
160c160
< 				</latex-image-code>
---
> 				</latex-image>
163c163
< 				<latex-image-code>
---
> 				<latex-image>
179c179
< 				</latex-image-code>
---
> 				</latex-image>
223,225c223,225
< 	<figure>
< 		<image width="25%">
< 			<latex-image-code>
---
> 	<sidebyside width="25%">
> 		<image>
> 			<latex-image>
229c229
< 			</latex-image-code>
---
> 			</latex-image>
231c231
< 	</figure>
---
> 	</sidebyside>
237c237
< 			<latex-image-code>
---
> 			<latex-image>
241c241
< 			</latex-image-code>
---
> 			</latex-image>
245c245
< 			<latex-image-code>
---
> 			<latex-image>
249c249
< 			</latex-image-code>
---
> 			</latex-image>
271,273c271,273
< 		 <figure>
< 		 	<image width="60%">
< 		 		<latex-image-code>
---
> 		 <sidebyside width="60%">
> 		 	<image>
> 		 		<latex-image>
281c281
< 		 		</latex-image-code>
---
> 		 		</latex-image>
285c285
< 		 </figure>
---
> 		 </sidebyside>
310c310
< 					<latex-image-code>
---
> 					<latex-image>
314c314
< 					</latex-image-code>
---
> 					</latex-image>
317c317
< 					<latex-image-code>
---
> 					<latex-image>
321c321
< 					</latex-image-code>
---
> 					</latex-image>
330c330
< 		Intuitively, graphs are <term>isomorphic</term> <index><main>isomorphic</main></index> if they are basically the same, or better yet, if they are the same except for the names of the vertices. To make the concept of renaming vertices precise, we give the following definitions:
---
> 		Intuitively, graphs are <term>isomorphic</term> <idx><h>isomorphic</h></idx> if they are basically the same, or better yet, if they are the same except for the names of the vertices. To make the concept of renaming vertices precise, we give the following definitions:
335,336c335,336
< 			<index><main>isomorphic</main></index> An
< 			<term>isomorphism</term><index><main>isomorphism</main></index> between two graphs <m>G_1</m> and <m>G_2</m> is a bijection <m>f:V_1 \to V_2</m> between the vertices of the graphs such that if <m>\{a,b\}</m> is an edge in <m>G_1</m> then <m>\{f(a), f(b)\}</m> is an edge in <m>G_2</m>.
---
> 			<idx><h>isomorphic</h></idx> An
> 			<term>isomorphism</term><idx><h>isomorphism</h></idx> between two graphs <m>G_1</m> and <m>G_2</m> is a bijection <m>f:V_1 \to V_2</m> between the vertices of the graphs such that if <m>\{a,b\}</m> is an edge in <m>G_1</m> then <m>\{f(a), f(b)\}</m> is an edge in <m>G_2</m>.
375c375
< 						<latex-image-code>
---
> 						<latex-image>
388c388
< 						</latex-image-code>
---
> 						</latex-image>
393c393
< 						<latex-image-code>
---
> 						<latex-image>
406c406
< 						</latex-image-code>
---
> 						</latex-image>
438c438
< 		Sometimes we will talk about a graph with a special name (like <m>K_n</m> or the <em>Peterson graph</em>) or perhaps draw a graph without any labels. In this case we are really referring to <em>all</em> graphs isomorphic to any copy of that particular graph. A collection of isomorphic graphs is often called an <term>isomorphism class</term><index><main>isomorphism class</main></index>.<fn>This is not unlike geometry, where we might have more than one copy of a particular triangle. There instead of <em>isomorphic</em> we say <em>congruent</em>.</fn>
---
> 		Sometimes we will talk about a graph with a special name (like <m>K_n</m> or the <em>Peterson graph</em>) or perhaps draw a graph without any labels. In this case we are really referring to <em>all</em> graphs isomorphic to any copy of that particular graph. A collection of isomorphic graphs is often called an <term>isomorphism class</term><idx><h>isomorphism class</h></idx>.<fn>This is not unlike geometry, where we might have more than one copy of a particular triangle. There instead of <em>isomorphic</em> we say <em>congruent</em>.</fn>
446c446
< 			<latex-image-code>\begin{tikzpicture}
---
> 			<latex-image>\begin{tikzpicture}
449c449
< 			    \end{tikzpicture}</latex-image-code>
---
> 			    \end{tikzpicture}</latex-image>
452c452
< 			<latex-image-code>\begin{tikzpicture}
---
> 			<latex-image>\begin{tikzpicture}
455c455
< 			    \end{tikzpicture}</latex-image-code>
---
> 			    \end{tikzpicture}</latex-image>
461,463c461,463
< 		 <figure>
< 			 <image width="20%">
< 			 <latex-image-code>\begin{tikzpicture}
---
> 		 <sidebyside width="20%">
> 			 <image>
> 			 <latex-image>\begin{tikzpicture}
467c467
< 					 \end{tikzpicture}</latex-image-code>
---
> 					 \end{tikzpicture}</latex-image>
469c469
< 		 </figure>
---
> 		 </sidebyside>
480c480
< 		  We say that <m>G_1 = (V_1, E_1)</m> is a <term>subgraph</term><index><main>subgraph</main></index> of <m>G_2 = (V_2, E_2)</m> provided <m>V_1 \subseteq V_2</m> and <m>E_1 \subseteq E_2</m>.
---
> 		  We say that <m>G_1 = (V_1, E_1)</m> is a <term>subgraph</term><idx><h>subgraph</h></idx> of <m>G_2 = (V_2, E_2)</m> provided <m>V_1 \subseteq V_2</m> and <m>E_1 \subseteq E_2</m>.
484c484
< 		  We say that <m>G_1 = (V_1, E_1)</m> is an <term>induced subgraph</term><index><main>subgraph</main><sub>induced</sub></index><index><main>induced subgraph</main></index> of <m>G_2 = (V_2, E_2)</m> provided <m>V_1 \subseteq V_2</m> and <m>E_1</m> contains all edges of <m>E_2</m> which are subsets of <m>V_1</m>.
---
> 		  We say that <m>G_1 = (V_1, E_1)</m> is an <term>induced subgraph</term><idx><h>subgraph</h><h>induced</h></idx><idx><h>induced subgraph</h></idx> of <m>G_2 = (V_2, E_2)</m> provided <m>V_1 \subseteq V_2</m> and <m>E_1</m> contains all edges of <m>E_2</m> which are subsets of <m>V_1</m>.
496c496
< 						<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> 						<latex-image>\begin{tikzpicture}[yscale=.8]
499c499
< 						    \end{tikzpicture}</latex-image-code>
---
> 						    \end{tikzpicture}</latex-image>
502c502
< 						<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> 						<latex-image>\begin{tikzpicture}[yscale=.8]
505c505
< 								\end{tikzpicture}</latex-image-code>
---
> 								\end{tikzpicture}</latex-image>
508c508
< 						<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> 						<latex-image>\begin{tikzpicture}[yscale=.8]
511c511
< 								\end{tikzpicture}</latex-image-code>
---
> 								\end{tikzpicture}</latex-image>
514c514
< 						<latex-image-code>\begin{tikzpicture}[yscale=.8]
---
> 						<latex-image>\begin{tikzpicture}[yscale=.8]
517c517
< 								\end{tikzpicture}</latex-image-code>
---
> 								\end{tikzpicture}</latex-image>
537c537
< 		That said, there are times we want to consider double (or more) edges and single edge loops. For example, the <q>graph</q> we drew for the Bridges of Königsberg problem had double edges because there really are two bridges connecting a particular island to the near shore. We will call these objects <term>multigraphs</term><index><main>multigraph</main></index>. This is a good name: a <em>multiset</em> is a set in which we are allowed to include a single element multiple times.
---
> 		That said, there are times we want to consider double (or more) edges and single edge loops. For example, the <q>graph</q> we drew for the Bridges of Königsberg problem had double edges because there really are two bridges connecting a particular island to the near shore. We will call these objects <term>multigraphs</term><idx><h>multigraph</h></idx>. This is a good name: a <em>multiset</em> is a set in which we are allowed to include a single element multiple times.
541,544c541,544
< 		The graphs above are also <term>connected</term><index><main>connected</main></index>: you can get from any vertex to any other vertex by following some path of edges. A graph that is not connected can be thought of as two separate graphs drawn close together. For example, the following graph is NOT connected because there is no path from <m>a</m> to <m>b</m>:
< 		<figure>
< 			<image xml:id="ex-gt-non-connected" width="33%">
< 			<latex-image-code>
---
> 		The graphs above are also <term>connected</term><idx><h>connected</h></idx>: you can get from any vertex to any other vertex by following some path of edges. A graph that is not connected can be thought of as two separate graphs drawn close together. For example, the following graph is NOT connected because there is no path from <m>a</m> to <m>b</m>:
> 		<sidebyside width="33%">
> 			<image xml:id="ex-gt-non-connected">
> 			<latex-image>
551c551
< 			</latex-image-code>
---
> 			</latex-image>
553c553
< 		</figure>
---
> 		</sidebyside>
561c561
< 		Vertices in a graph do not always have edges between them. If we add all possible edges, then the resulting graph is called <term>complete</term><index><main>complete graph</main></index>. That is, a graph is complete if every pair of vertices is connected by an edge. Since a graph is determined completely by which vertices are adjacent to which other vertices, there is only one complete graph with a given number of vertices. We give these a special name: <m>K_n</m><notation><usage>K_n</usage><description>the complete graph on <m>n</m> vertices</description></notation> is the complete graph on <m>n</m> vertices.
---
> 		Vertices in a graph do not always have edges between them. If we add all possible edges, then the resulting graph is called <term>complete</term><idx><h>complete graph</h></idx>. That is, a graph is complete if every pair of vertices is connected by an edge. Since a graph is determined completely by which vertices are adjacent to which other vertices, there is only one complete graph with a given number of vertices. We give these a special name: <m>K_n</m><notation><usage>K_n</usage><description>the complete graph on <m>n</m> vertices</description></notation> is the complete graph on <m>n</m> vertices.
584c584
< 		One final definition: we say a graph is <term>bipartite</term><index><main>bipartite</main></index> if the vertices can be divided into two sets, <m>A</m> and <m>B</m>, with no two vertices in <m>A</m> adjacent and no two vertices in <m>B</m> adjacent. The vertices in <m>A</m> can be adjacent to some or all of the vertices in <m>B</m>. If each vertex in <m>A</m> is adjacent to all the vertices in <m>B</m>, then the graph is a <term>complete bipartite graph</term>, and gets a special name: <m>K_{m,n}</m>, where <m>|A| = m</m> and <m>|B| = n</m>. The graph in the houses and utilities puzzle is <m>K_{3,3}</m>.
---
> 		One final definition: we say a graph is <term>bipartite</term><idx><h>bipartite</h></idx> if the vertices can be divided into two sets, <m>A</m> and <m>B</m>, with no two vertices in <m>A</m> adjacent and no two vertices in <m>B</m> adjacent. The vertices in <m>A</m> can be adjacent to some or all of the vertices in <m>B</m>. If each vertex in <m>A</m> is adjacent to all the vertices in <m>B</m>, then the graph is a <term>complete bipartite graph</term>, and gets a special name: <m>K_{m,n}</m>, where <m>|A| = m</m> and <m>|B| = n</m>. The graph in the houses and utilities puzzle is <m>K_{3,3}</m>.
607c607
< 				<latex-image-code>
---
> 				<latex-image>
617c617
< 				</latex-image-code>
---
> 				</latex-image>
620c620
< 				<latex-image-code>
---
> 				<latex-image>
625c625
< 				</latex-image-code>
---
> 				</latex-image>
628c628
< 				<latex-image-code>
---
> 				<latex-image>
633c633
< 				</latex-image-code>
---
> 				</latex-image>
636c636
< 				<latex-image-code>
---
> 				<latex-image>
641c641
< 				</latex-image-code>
---
> 				</latex-image>
657c657
< 					<p><index><main>graph</main></index> A collection of
---
> 					<p><idx><h>graph</h></idx> A collection of
664c664
< 					<p><index><main>adjacent</main></index> Two vertices are
---
> 					<p><idx><h>adjacent</h></idx> Two vertices are
671c671
< 					<p><index><main>bipartite</main></index> A graph for which it is possible to divide the vertices into two disjoint sets such that there are no edges between any two vertices in the same set.</p>
---
> 					<p><idx><h>bipartite</h></idx> A graph for which it is possible to divide the vertices into two disjoint sets such that there are no edges between any two vertices in the same set.</p>
681c681
< 					<p><index><main>complete graph</main></index> A graph in which every pair of vertices is adjacent.</p>
---
> 					<p><idx><h>complete graph</h></idx> A graph in which every pair of vertices is adjacent.</p>
686c686
< 					<p><index><main>connected</main></index> A graph is
---
> 					<p><idx><h>connected</h></idx> A graph is
693c693
< 					<p><index><main>chromatic number</main></index> The minimum number of colors required in a proper vertex coloring of the graph.
---
> 					<p><idx><h>chromatic number</h></idx> The minimum number of colors required in a proper vertex coloring of the graph.
699c699
< 					<p><index><main>cycle</main></index> A path (see below) that starts and stops at the same vertex, but contains no other repeated vertices.</p>
---
> 					<p><idx><h>cycle</h></idx> A path (see below) that starts and stops at the same vertex, but contains no other repeated vertices.</p>
704c704
< 					<p><index><main>degree</main></index> The number of edges incident to a vertex.</p>
---
> 					<p><idx><h>degree</h></idx> The number of edges incident to a vertex.</p>
715c715
< 					<p><index><main>Euler path</main></index> An Euler path which starts and stops at the same vertex.</p>
---
> 					<p><idx><h>Euler path</h></idx> An Euler path which starts and stops at the same vertex.</p>
720c720
< 					<p><index><main>multigraph</main></index> A
---
> 					<p><idx><h>multigraph</h></idx> A
727c727
< 					<p><index><main>planar</main></index> A graph which can be drawn (in the plane) without any edges crossing.</p>
---
> 					<p><idx><h>planar</h></idx> A graph which can be drawn (in the plane) without any edges crossing.</p>
732c732
< 					<p><index><main>subgraph</main></index> We say that <m>H</m> is a
---
> 					<p><idx><h>subgraph</h></idx> We say that <m>H</m> is a
739c739
< 					<p><index><main>tree</main></index> A (connected) graph with no cycles. (A non-connected graph with no cycles is called a
---
> 					<p><idx><h>tree</h></idx> A (connected) graph with no cycles. (A non-connected graph with no cycles is called a
746c746
< 					<p><index><main>vertex coloring</main></index> An assignment of colors to each of the vertices of a graph. A vertex coloring is
---
> 					<p><idx><h>vertex coloring</h></idx> An assignment of colors to each of the vertices of a graph. A vertex coloring is
752c752
< 					<p><index><main>walk</main></index> A sequence of vertices such that consecutive vertices (in the sequence) are adjacent (in the graph). A walk in which no vertex is repeated is called
---
> 					<p><idx><h>walk</h></idx> A sequence of vertices such that consecutive vertices (in the sequence) are adjacent (in the graph). A walk in which no vertex is repeated is called
diff normal/sec_gt-matchings.mbx clean/sec_gt-matchings.mbx
12,14c12,14
< <figure>
<   <image width="50%">
<   <latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="50%">
>   <image>
>   <latex-image>\begin{tikzpicture}
26c26
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
28c28
< </figure>
---
> </sidebyside>
41c41
< Suppose you have a bipartite graph <m>G</m>. This will consist of two sets of vertices <m>A</m> and <m>B</m> with some edges connecting some vertices of <m>A</m> to some vertices in <m>B</m> (but of course, no edges between two vertices both in <m>A</m> or both in <m>B</m>). A <term>matching of <m>A</m></term><index><main>matching</main></index> is a subset of the edges for which each vertex of <m>A</m> belongs to exactly one edge of the subset, and no vertex in <m>B</m> belongs to more than one edge in the subset. In practice we will assume that <m>|A| = |B|</m> (the two sets have the same number of vertices) so this says that every vertex in the graph belongs to exactly one edge in the matching.<fn>Note: what we are calling a <em>matching</em> is sometimes called a <em>perfect matching</em> or <em>complete matching</em>.  This is because in it interesting to look at non-perfect matchings as well. We will call those <em>partial</em> matchings.</fn>
---
> Suppose you have a bipartite graph <m>G</m>. This will consist of two sets of vertices <m>A</m> and <m>B</m> with some edges connecting some vertices of <m>A</m> to some vertices in <m>B</m> (but of course, no edges between two vertices both in <m>A</m> or both in <m>B</m>). A <term>matching of <m>A</m></term><idx><h>matching</h></idx> is a subset of the edges for which each vertex of <m>A</m> belongs to exactly one edge of the subset, and no vertex in <m>B</m> belongs to more than one edge in the subset. In practice we will assume that <m>|A| = |B|</m> (the two sets have the same number of vertices) so this says that every vertex in the graph belongs to exactly one edge in the matching.<fn>Note: what we are calling a <em>matching</em> is sometimes called a <em>perfect matching</em> or <em>complete matching</em>.  This is because in it interesting to look at non-perfect matchings as well. We will call those <em>partial</em> matchings.</fn>
62c62
< To make this more graph-theoretic, say you have a set <m>S \subseteq A</m> of vertices. Define <m>N(S)</m><notation><usage>N(S)</usage><description>the set of neighbors of <m>S</m>.</description></notation> to be the set of all the <term>neighbors</term><index><main>neighbors</main></index> of vertices in <m>S</m>. That is, <m>N(S)</m> contains all the vertices (in <m>B</m>) which are adjacent to at least one of the vertices in <m>S</m>. (In the student/topic graph, <m>N(S)</m> is the set of topics liked by the students of <m>S</m>.) Our discussion above can be summarized as follows:
---
> To make this more graph-theoretic, say you have a set <m>S \subseteq A</m> of vertices. Define <m>N(S)</m><notation><usage>N(S)</usage><description>the set of neighbors of <m>S</m>.</description></notation> to be the set of all the <term>neighbors</term><idx><h>neighbors</h></idx> of vertices in <m>S</m>. That is, <m>N(S)</m> contains all the vertices (in <m>B</m>) which are adjacent to at least one of the vertices in <m>S</m>. (In the student/topic graph, <m>N(S)</m> is the set of topics liked by the students of <m>S</m>.) Our discussion above can be summarized as follows:
67c67
< <index><main>matching condition</main></index>
---
> <idx><h>matching condition</h></idx>
83c83
< <index><main>Hall's Marriage Theorem</main></index>
---
> <idx><h>Hall's Marriage Theorem</h></idx>
diff normal/sec_gt-paths.mbx clean/sec_gt-paths.mbx
18c18
<   <latex-image-code>\begin{tikzpicture}[scale=0.9]
---
>   <latex-image>\begin{tikzpicture}[scale=0.9]
21c21
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
24c24
<   <latex-image-code>\begin{tikzpicture}[scale=0.9]
---
>   <latex-image>\begin{tikzpicture}[scale=0.9]
26c26
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
29c29
<   <latex-image-code>\begin{tikzpicture}[scale=0.9]
---
>   <latex-image>\begin{tikzpicture}[scale=0.9]
32c32
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
35c35
<   <latex-image-code>\begin{tikzpicture}[yscale=.45]
---
>   <latex-image>\begin{tikzpicture}[yscale=.45]
38c38
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
62,64c62,64
< <figure>
<   <image width="54%">
<   <latex-image-code>\begin{tikzpicture}[scale=0.9]
---
> <sidebyside width="54%">
>   <image>
>   <latex-image>\begin{tikzpicture}[scale=0.9]
72c72
<    \end{tikzpicture}</latex-image-code>
---
>    \end{tikzpicture}</latex-image>
74c74
< </figure>
---
> </sidebyside>
90,92c90,92
< <figure>
<   <image width="22%">
<   <latex-image-code>\begin{tikzpicture}[scale=1, yscale=.5]
---
> <sidebyside width="22%">
>   <image>
>   <latex-image>\begin{tikzpicture}[scale=1, yscale=.5]
95c95
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
97c97
< </figure>
---
> </sidebyside>
107,109c107,109
< <figure>
<   <image width="23%">
<   <latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="23%">
>   <image>
>   <latex-image>\begin{tikzpicture}
112c112
<    \end{tikzpicture}</latex-image-code>
---
>    \end{tikzpicture}</latex-image>
114c114
< </figure>
---
> </sidebyside>
157c157
< Suppose you wanted to tour Königsberg in such a way where you visit each land mass (the two islands and both banks) exactly once. This can be done. In graph theory terms, we are asking whether there is a path which visits every vertex exactly once. Such a path is called a <term>Hamilton path</term> (or <term>Hamiltonian path</term>)<index><main>Hamilton path</main></index>.  We could also consider <term>Hamilton cycles</term>, which are Hamliton paths which start and stop at the same vertex.
---
> Suppose you wanted to tour Königsberg in such a way where you visit each land mass (the two islands and both banks) exactly once. This can be done. In graph theory terms, we are asking whether there is a path which visits every vertex exactly once. Such a path is called a <term>Hamilton path</term> (or <term>Hamiltonian path</term>)<idx><h>Hamilton path</h></idx>.  We could also consider <term>Hamilton cycles</term>, which are Hamliton paths which start and stop at the same vertex.
168c168
<         <latex-image-code>
---
>         <latex-image>
177c177
<         </latex-image-code>
---
>         </latex-image>
180c180
<         <latex-image-code>
---
>         <latex-image>
189c189
<         </latex-image-code>
---
>         </latex-image>
201,203c201,203
<     <figure>
<       <image width="20%">
<         <latex-image-code>
---
>     <sidebyside width="20%">
>       <image>
>         <latex-image>
213c213
<         </latex-image-code>
---
>         </latex-image>
215c215
<     </figure>
---
>     </sidebyside>
227c227
< It appears that finding Hamilton paths would be easier because graphs often have more edges than vertices, so there are fewer requirements to be met. However, nobody knows whether this is true. There is no known simple test for whether a graph has a Hamilton path. For small graphs this is not a problem, but as the size of the graph grows, it gets harder and harder to check wither there is a Hamilton path. In fact, this is an example of a question which as far as we know is too difficult for computers to solve; it is an example of a problem which is NP-complete<index><main>NP-complete</main></index>.
---
> It appears that finding Hamilton paths would be easier because graphs often have more edges than vertices, so there are fewer requirements to be met. However, nobody knows whether this is true. There is no known simple test for whether a graph has a Hamilton path. For small graphs this is not a problem, but as the size of the graph grows, it gets harder and harder to check wither there is a Hamilton path. In fact, this is an example of a question which as far as we know is too difficult for computers to solve; it is an example of a problem which is NP-complete<idx><h>NP-complete</h></idx>.
diff normal/sec_gt-planar.mbx clean/sec_gt-planar.mbx
27c27
< When is it possible to draw a graph so that none of the edges cross? If this <em>is</em> possible, we say the graph is <term>planar</term><index><main>planar</main></index> (since you can draw it on the <em>plane</em>).
---
> When is it possible to draw a graph so that none of the edges cross? If this <em>is</em> possible, we say the graph is <term>planar</term><idx><h>planar</h></idx> (since you can draw it on the <em>plane</em>).
33,35c33,35
< <figure>
<   <image width="20%">
<   <latex-image-code>\begin{tikzpicture}[scale=.7, xscale=1.5]
---
> <sidebyside width="20%">
>   <image>
>   <latex-image>\begin{tikzpicture}[scale=.7, xscale=1.5]
37c37
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
39c39
< </figure>
---
> </sidebyside>
43,45c43,45
< <figure>
<   <image width="25%">
<   <latex-image-code>\begin{tikzpicture}[scale=.7, xscale=1.5]
---
> <sidebyside width="25%">
>   <image>
>   <latex-image>\begin{tikzpicture}[scale=.7, xscale=1.5]
47c47
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
49c49
< </figure>
---
> </sidebyside>
55c55
< When a planar graph is drawn without edges crossing, the edges and vertices of the graph divide the plane into regions. We will call each region a <term>face</term><index><main>faces</main></index>. The graph above has 3 faces (yes, we <b>do</b> include the <q>outside</q> region as a face). The number of faces does not change no matter how you draw the graph (as long as you do so without the edges crossing), so it makes sense to ascribe the number of faces as a property of the planar graph.
---
> When a planar graph is drawn without edges crossing, the edges and vertices of the graph divide the plane into regions. We will call each region a <term>face</term><idx><h>faces</h></idx>. The graph above has 3 faces (yes, we <b>do</b> include the <q>outside</q> region as a face). The number of faces does not change no matter how you draw the graph (as long as you do so without the edges crossing), so it makes sense to ascribe the number of faces as a property of the planar graph.
64c64
<   <latex-image-code>\begin{tikzpicture}
---
>   <latex-image>\begin{tikzpicture}
66c66
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
69c69
<   <latex-image-code>\begin{tikzpicture}
---
>   <latex-image>\begin{tikzpicture}
72c72
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
86c86
< <index><main>Euler's formula</main></index>
---
> <idx><h>Euler's formula</h></idx>
96,98c96,98
< <figure>
<   <image width="10%">
<   <latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="10%">
>   <image>
>   <latex-image>\begin{tikzpicture}
100c100
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
102c102
< </figure>
---
> </sidebyside>
110c110
<   <latex-image-code>\begin{tikzpicture}
---
>   <latex-image>\begin{tikzpicture}
113c113
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
116c116
<   <latex-image-code>\begin{tikzpicture}
---
>   <latex-image>\begin{tikzpicture}
119c119
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
165,167c165,167
< <figure>
<   <image width="20%">
<   <latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="20%">
>   <image>
>   <latex-image>\begin{tikzpicture}
170c170
<     \end{tikzpicture}</latex-image-code>
---
>     \end{tikzpicture}</latex-image>
172c172
< </figure>
---
> </sidebyside>
210,212c210,212
< <figure>
<   <image width="20%">
<   <latex-image-code>\begin{tikzpicture}[yscale=1.2]
---
> <sidebyside width="20%">
>   <image>
>   <latex-image>\begin{tikzpicture}[yscale=1.2]
214c214
<         \end{tikzpicture}</latex-image-code>
---
>         \end{tikzpicture}</latex-image>
216c216
< </figure>
---
> </sidebyside>
251c251
< In general, if we let <m>g</m> be the size of the smallest cycle in a graph (<m>g</m> stands for <em>girth</em><index><main>girth</main></index>, which is the technical term for this) then for any planar graph we have <m>gf \le 2e</m>. When this disagrees with Euler's formula, we know for sure that the graph cannot be planar.
---
> In general, if we let <m>g</m> be the size of the smallest cycle in a graph (<m>g</m> stands for <em>girth</em><idx><h>girth</h></idx>, which is the technical term for this) then for any planar graph we have <m>gf \le 2e</m>. When this disagrees with Euler's formula, we know for sure that the graph cannot be planar.
260c260
< A cube<index><main>cube</main></index> is an example of a convex polyhedron. It contains 6 identical squares for its faces, 8 vertices, and 12 edges. The cube is a <term>regular polyhedron</term> (also known as a <term>Platonic solid</term><index><main>Platonic solids</main></index>) because each face is an identical regular polygon and each vertex joins an equal number of faces.
---
> A cube<idx><h>cube</h></idx> is an example of a convex polyhedron. It contains 6 identical squares for its faces, 8 vertices, and 12 edges. The cube is a <term>regular polyhedron</term> (also known as a <term>Platonic solid</term><idx><h>Platonic solids</h></idx>) because each face is an identical regular polygon and each vertex joins an equal number of faces.
268c268
< Another area of mathematics where you might have heard the terms <q>vertex,</q> <q>edge,</q> and <q>face</q> is geometry. A <term>polyhedron</term><index><main>polyhedron</main></index> is a geometric solid made up of flat polygonal faces joined at edges and vertices. We are especially interested in <term>convex</term><index><main>convex</main></index> polyhedra, which means that any line segment connecting two points on the interior of the polyhedron must be entirely contained inside the polyhedron.<fn>An alternative definition for convex is that the internal angle formed by any two faces must be less than <m>180\deg</m>.</fn>
---
> Another area of mathematics where you might have heard the terms <q>vertex,</q> <q>edge,</q> and <q>face</q> is geometry. A <term>polyhedron</term><idx><h>polyhedron</h></idx> is a geometric solid made up of flat polygonal faces joined at edges and vertices. We are especially interested in <term>convex</term><idx><h>convex</h></idx> polyhedra, which means that any line segment connecting two points on the interior of the polyhedron must be entirely contained inside the polyhedron.<fn>An alternative definition for convex is that the internal angle formed by any two faces must be less than <m>180\deg</m>.</fn>
274,276c274,276
< <figure>
<   <image width="20%">
<   <latex-image-code>\begin{tikzpicture}
---
> <sidebyside width="20%">
>   <image>
>   <latex-image>\begin{tikzpicture}
280c280
<   \end{tikzpicture}</latex-image-code>
---
>   \end{tikzpicture}</latex-image>
282c282
< </figure>
---
> </sidebyside>
335c335
<     We need <m>k</m> and <m>f</m> to both be positive integers. Note that <m>\frac{6f}{4+f}</m> is an increasing function for positive <m>f</m>, and has a horizontal asymptote at 6. Thus the only possible values for <m>k</m> are 3, 4, and 5. Each of these are possible. To get <m>k = 3</m>, we need <m>f = 4</m> (this is the tetrahedron)<index><main>tetrahedron</main></index>. For <m>k = 4</m> we take <m>f = 8</m> (the octahedron)<index><main>octahedron</main></index>. For <m>k = 5</m> take <m>f = 20</m> (the icosahedron)<index><main>icosahedron</main></index>. Thus there are exactly three regular polyhedra with triangles for faces.
---
>     We need <m>k</m> and <m>f</m> to both be positive integers. Note that <m>\frac{6f}{4+f}</m> is an increasing function for positive <m>f</m>, and has a horizontal asymptote at 6. Thus the only possible values for <m>k</m> are 3, 4, and 5. Each of these are possible. To get <m>k = 3</m>, we need <m>f = 4</m> (this is the tetrahedron)<idx><h>tetrahedron</h></idx>. For <m>k = 4</m> we take <m>f = 8</m> (the octahedron)<idx><h>octahedron</h></idx>. For <m>k = 5</m> take <m>f = 20</m> (the icosahedron)<idx><h>icosahedron</h></idx>. Thus there are exactly three regular polyhedra with triangles for faces.
368c368
<     Now the horizontal asymptote is at <m>\frac{10}{3}</m>. This is less than 4, so we can only hope of making <m>k = 3</m>. We can do so by using 12 pentagons, getting the dodecahedron<index><main>dodecahedron</main></index>. This is the only regular polyhedron with pentagons as faces.
---
>     Now the horizontal asymptote is at <m>\frac{10}{3}</m>. This is less than 4, so we can only hope of making <m>k = 3</m>. We can do so by using 12 pentagons, getting the dodecahedron<idx><h>dodecahedron</h></idx>. This is the only regular polyhedron with pentagons as faces.
diff normal/sec_intro-functions.mbx clean/sec_intro-functions.mbx
9,11c9,11
<       <term>function</term><index><main>function</main></index> is a rule that assigns each input exactly one output.  We call the output the <term>image</term> of the input.  The set of all inputs for a function is called the
<       <term>domain</term><index><main>domain</main></index>. The set of all allowable outputs is called the
<       <term>codomain</term><index><main>codomain</main></index>. We would write <m>f:X \to Y</m> to describe a function with name <m>f</m>, domain <m>X</m> and codomain <m>Y</m>. This does not tell us <em>which</em> function <m>f</m> is though. To define the function, we must describe the rule. This is often done by giving a formula to compute the output for any input (although this is certainly not the only way to describe the rule). </p>
---
>       <term>function</term><idx><h>function</h></idx> is a rule that assigns each input exactly one output.  We call the output the <term>image</term> of the input.  The set of all inputs for a function is called the
>       <term>domain</term><idx><h>domain</h></idx>. The set of all allowable outputs is called the
>       <term>codomain</term><idx><h>codomain</h></idx>. We would write <m>f:X \to Y</m> to describe a function with name <m>f</m>, domain <m>X</m> and codomain <m>Y</m>. This does not tell us <em>which</em> function <m>f</m> is though. To define the function, we must describe the rule. This is often done by giving a formula to compute the output for any input (although this is certainly not the only way to describe the rule). </p>
14c14
<       <term>range</term><index><main>range</main></index> of the function (in this case, the range is <m>\{3, 4, 7, 12, 19, 28, \ldots\}</m>, all the natural numbers that are 3 more than a perfect square).
---
>       <term>range</term><idx><h>range</h></idx> of the function (in this case, the range is <m>\{3, 4, 7, 12, 19, 28, \ldots\}</m>, all the natural numbers that are 3 more than a perfect square).
35,37c35,37
<                 <figure>
<                   <image xml:id="arrow-function-example" width="17%">
<                     <latex-image-code>
---
>                 <sidebyside width="17%">
>                   <image xml:id="arrow-function-example">
>                     <latex-image>
43c43
<                     </latex-image-code>
---
>                     </latex-image>
45c45
<                 </figure>
---
>                 </sidebyside>
56,58c56,58
<     <figure>
<       <image xml:id="discrete-function-graph" width="40%">
<         <latex-image-code>
---
>     <sidebyside width="40%">
>       <image xml:id="discrete-function-graph">
>         <latex-image>
65c65
<         </latex-image-code>
---
>         </latex-image>
67c67
<     </figure>
---
>     </sidebyside>
75c75
<       <table>
---
>       <sidebyside>
94c94
<       </table>
---
>       </sidebyside>
117c117
<           <figure>
---
>           
119c119
<               <latex-image-code>
---
>               <latex-image>
127c127
<               </latex-image-code>
---
>               </latex-image>
129c129
<           </figure>
---
>           
133c133
<           <figure>
---
>           
135c135
<               <latex-image-code>
---
>               <latex-image>
144c144
<               </latex-image-code>
---
>               </latex-image>
146c146
<           </figure>
---
>           
150c150
<           <figure>
---
>           
152c152
<               <latex-image-code>
---
>               <latex-image>
162c162
<               </latex-image-code>
---
>               </latex-image>
164c164
<           </figure>
---
>           
183c183
<           <figure>
---
>           
185c185
<               <latex-image-code>
---
>               <latex-image>
192c192
<               </latex-image-code>
---
>               </latex-image>
194c194
<           </figure>
---
>           
196c196
<           <figure>
---
>           
198c198
<               <latex-image-code>
---
>               <latex-image>
207c207
<               </latex-image-code>
---
>               </latex-image>
209c209
<           </figure>
---
>           
232,233c232,233
<       <term>onto</term><index><main>onto</main></index> or that the function maps the domain <em>onto</em> the codomain. This terminology should make sense: the function puts the domain (entirely) on top of the codomain. The fancy math term for an onto function is a
<       <term>surjection</term><index><main>surjection</main></index>, and we say that an onto function is a
---
>       <term>onto</term><idx><h>onto</h></idx> or that the function maps the domain <em>onto</em> the codomain. This terminology should make sense: the function puts the domain (entirely) on top of the codomain. The fancy math term for an onto function is a
>       <term>surjection</term><idx><h>surjection</h></idx>, and we say that an onto function is a
241c241
<       <figure>
---
>       
243c243
<           <latex-image-code>
---
>           <latex-image>
253c253
<           </latex-image-code>
---
>           </latex-image>
256c256
<       </figure>
---
>       
258c258
<       <figure>
---
>       
260c260
<           <latex-image-code>
---
>           <latex-image>
270c270
<           </latex-image-code>
---
>           </latex-image>
273c273
<       </figure>
---
>       
287,289c287,289
<             <figure>
<               <image xml:id="ex-surj-q" width="20%">
<                 <latex-image-code>
---
>             <sidebyside width="20%">
>               <image xml:id="ex-surj-q">
>                 <latex-image>
295c295
<                 </latex-image-code>
---
>                 </latex-image>
297c297
<             </figure>
---
>             </sidebyside>
311,312c311,312
<       <term>one-to-one</term><index><main>one-to-one</main></index>. Again, this terminology makes sense: we are sending at most one element from the domain to one element from the codomain. One input to one output. The fancy math term for a one-to-one function is an
<       <term>injection</term><index><main>injection</main></index>. We call one-to-one functions
---
>       <term>one-to-one</term><idx><h>one-to-one</h></idx>. Again, this terminology makes sense: we are sending at most one element from the domain to one element from the codomain. One input to one output. The fancy math term for a one-to-one function is an
>       <term>injection</term><idx><h>injection</h></idx>. We call one-to-one functions
320c320
<       <figure>
---
>       
322c322
<           <latex-image-code>
---
>           <latex-image>
332c332
<           </latex-image-code>
---
>           </latex-image>
335c335
<       </figure>
---
>       
338c338
<       <figure>
---
>       
340c340
<           <latex-image-code>
---
>           <latex-image>
350c350
<           </latex-image-code>
---
>           </latex-image>
355c355
<       </figure>
---
>       
368,370c368,370
<             <figure>
<               <image width="20%">
<                 <latex-image-code>
---
>             <sidebyside width="20%">
>               <image>
>                 <latex-image>
376c376
<                 </latex-image-code>
---
>                 </latex-image>
378c378
<             </figure>
---
>             </sidebyside>
392c392
<       <term>bijection</term><index><main>bijection</main></index>, or that the function is a
---
>       <term>bijection</term><idx><h>bijection</h></idx>, or that the function is a
407c407
<       <term>complete inverse image</term><index><main>inverse image</main></index> of <m>y</m> under <m>f</m>.
---
>       <term>complete inverse image</term><idx><h>inverse image</h></idx> of <m>y</m> under <m>f</m>.
diff normal/sec_intro-intro.mbx clean/sec_intro-intro.mbx
45,47c45,47
<       <figure>
<       <image xml:id="two-chests" width="80%">
<       <latex-image-code>\begin{tikzpicture}
---
>       <sidebyside width="80%">
>       <image xml:id="two-chests">
>       <latex-image>\begin{tikzpicture}
52c52
<       \end{tikzpicture}</latex-image-code>
---
>       \end{tikzpicture}</latex-image>
54c54
<     </figure>
---
>     </sidebyside>
diff normal/sec_intro-sets.mbx clean/sec_intro-sets.mbx
14c14
<       For us, a <term>set</term> <index><main>set</main></index> will simply be an unordered collection of objects. Two examples: we could consider the set of all actors who have played <em>The Doctor</em> on <em>Doctor Who</em><index><main>Doctor Who</main></index>, or the set of natural numbers between 1 and 10 inclusive. In the first case, Tom Baker is a element (or member) of the set, while Idris Elba, among many others, is not an element of the set. Also, the two examples are of different sets. Two sets are equal exactly if they contain the exact same elements. For example, the set containing all of the vowels in the declaration of independence is precisely the same set as the set of vowels in the word <q>questionably</q> (namely, all of them); we do not care about order or repetitions, just whether the element is in the set or not.
---
>       For us, a <term>set</term> <idx><h>set</h></idx> will simply be an unordered collection of objects. Two examples: we could consider the set of all actors who have played <em>The Doctor</em> on <em>Doctor Who</em><idx><h>Doctor Who</h></idx>, or the set of natural numbers between 1 and 10 inclusive. In the first case, Tom Baker is a element (or member) of the set, while Idris Elba, among many others, is not an element of the set. Also, the two examples are of different sets. Two sets are equal exactly if they contain the exact same elements. For example, the set containing all of the vowels in the declaration of independence is precisely the same set as the set of vowels in the word <q>questionably</q> (namely, all of them); we do not care about order or repetitions, just whether the element is in the set or not.
114,116c114,116
<               <index>
<                 <main>integers</main>
<               </index> (positive and negative whole numbers, written <m>\Z</m>). In other words, <m>\{\ldots, -2, -1, 0, 1, 2, \ldots\}</m>.
---
>               <idx>
>                 <h>integers</h>
>               </idx> (positive and negative whole numbers, written <m>\Z</m>). In other words, <m>\{\ldots, -2, -1, 0, 1, 2, \ldots\}</m>.
138c138
<           <p>The <term>empty set</term> is the set which contains no elements. <notation> <usage>\emptyset</usage><description>the empty set</description> </notation>  <index> <main>empty set</main> </index> </p>
---
>           <p>The <term>empty set</term> is the set which contains no elements. <notation> <usage>\emptyset</usage><description>the empty set</description> </notation>  <idx> <h>empty set</h> </idx> </p>
146,148c146,148
<     <index>
<       <main>natural numbers</main>
<     </index></p>
---
>     <idx>
>       <h>natural numbers</h>
>     </idx></p>
150,151c150,151
<   <li><title><m>\Z</m></title> <p>The set of integers. That is, <m>\Z = \{\ldots, -2, -1, 0, 1, 2, 3, \ldots\}</m>.    <index> <main>integers</main> </index> <notation> <usage>\Z</usage><description>the set of integers</description> </notation></p> </li>
<   <li><title><m>\Q</m></title> <p>The set of rational numbers.  <notation> <usage>\Q</usage><description>the set of rational numbers</description> </notation> <index> <main>rationals</main> </index></p>
---
>   <li><title><m>\Z</m></title> <p>The set of integers. That is, <m>\Z = \{\ldots, -2, -1, 0, 1, 2, 3, \ldots\}</m>.    <idx> <h>integers</h> </idx> <notation> <usage>\Z</usage><description>the set of integers</description> </notation></p> </li>
>   <li><title><m>\Q</m></title> <p>The set of rational numbers.  <notation> <usage>\Q</usage><description>the set of rational numbers</description> </notation> <idx> <h>rationals</h> </idx></p>
153c153
< <li><title><m>\R</m></title> <p>The set of real numbers.</p>      <index> <main>reals</main> </index> <notation> <usage>\R</usage><description>the set of real numbers</description> </notation>
---
> <li><title><m>\R</m></title> <p>The set of real numbers.</p>      <idx> <h>reals</h> </idx> <notation> <usage>\R</usage><description>the set of real numbers</description> </notation>
156c156
< <p>The <term>power set</term> of any set <m>A</m> is the set of all subsets of <m>A</m>.</p>      <index> <main>power set</main> </index> <notation> <usage>\pow(A)</usage><description>the power set of <m>A</m></description> </notation>
---
> <p>The <term>power set</term> of any set <m>A</m> is the set of all subsets of <m>A</m>.</p>      <idx> <h>power set</h> </idx> <notation> <usage>\pow(A)</usage><description>the power set of <m>A</m></description> </notation>
184c184
<             <p><m>A \cap B</m> is the <term>intersection of <m>A</m> and <m>B</m></term>: the set containing all elements which are elements of both <m>A</m> and <m>B</m>. <notation> <usage>\cap</usage> <description> set intersection </description></notation><index> <main>intersection</main> </index></p>
---
>             <p><m>A \cap B</m> is the <term>intersection of <m>A</m> and <m>B</m></term>: the set containing all elements which are elements of both <m>A</m> and <m>B</m>. <notation> <usage>\cap</usage> <description> set intersection </description></notation><idx> <h>intersection</h> </idx></p>
187c187
<             <p><m>A \cup B</m> is the <term>union of <m>A</m> and <m>B</m></term>: is the set containing all elements which are elements of <m>A</m> or <m>B</m> or both.<notation> <usage>\cup</usage> <description> set union </description></notation><index> <main>union</main> </index></p>
---
>             <p><m>A \cup B</m> is the <term>union of <m>A</m> and <m>B</m></term>: is the set containing all elements which are elements of <m>A</m> or <m>B</m> or both.<notation> <usage>\cup</usage> <description> set union </description></notation><idx> <h>union</h> </idx></p>
200c200
<             <index> <main>cardinality</main></index></p>
---
>             <idx> <h>cardinality</h></idx></p>
259,261c259,261
<       <index>
<         <main>subset</main>
<       </index> of <m>B</m>, or in symbols <m>A \subset B</m> or <m>A \subseteq B</m>. Both symbols are read <q>is a subset of.</q> The difference is that sometimes we want to say that <m>A</m> is either equal to or is a subset of <m>B</m>, in which case we use <m>\subseteq</m>. This is analogous to the difference between <m>\lt</m> and <m>\le</m>.
---
>       <idx>
>         <h>subset</h>
>       </idx> of <m>B</m>, or in symbols <m>A \subset B</m> or <m>A \subseteq B</m>. Both symbols are read <q>is a subset of.</q> The difference is that sometimes we want to say that <m>A</m> is either equal to or is a subset of <m>B</m>, in which case we use <m>\subseteq</m>. This is analogous to the difference between <m>\lt</m> and <m>\le</m>.
343,345c343,345
<       <index>
<         <main>power set</main>
<       </index> of <m>A</m>, and write it <m>\pow(A)</m>.
---
>       <idx>
>         <h>power set</h>
>       </idx> of <m>A</m>, and write it <m>\pow(A)</m>.
371c371
<       Another way to compare sets is by their <em>size</em>. Notice that in the example above, <m>A</m> has 6 elements and <m>B</m>, <m>C</m>, and <m>D</m> all have 3 elements. The size of a set is called the set's <term>cardinality</term> <index> <main>cardinality</main> </index>. We would write <m>|A| = 6</m>, <m>|B| = 3</m>, and so on. For sets that have a finite number of elements, the cardinality of the set is simply the number of elements in the set. Note that the cardinality of <m>\{ 1, 2, 3, 2, 1\}</m> is 3. We do not count repeats (in fact, <m>\{1, 2, 3, 2, 1\}</m> is exactly the same set as <m>\{1, 2, 3\}</m>). There are sets with infinite cardinality, such as <m>\N</m>, the set of rational numbers (written <m>\mathbb Q</m>), the set of even natural numbers, and the set of real numbers (<m>\mathbb R</m>). It is possible to distinguish between different infinite cardinalities, but that is beyond the scope of this text. For us, a set will either be infinite, or finite; if it is finite, the we can determine its cardinality by counting elements.
---
>       Another way to compare sets is by their <em>size</em>. Notice that in the example above, <m>A</m> has 6 elements and <m>B</m>, <m>C</m>, and <m>D</m> all have 3 elements. The size of a set is called the set's <term>cardinality</term> <idx> <h>cardinality</h> </idx>. We would write <m>|A| = 6</m>, <m>|B| = 3</m>, and so on. For sets that have a finite number of elements, the cardinality of the set is simply the number of elements in the set. Note that the cardinality of <m>\{ 1, 2, 3, 2, 1\}</m> is 3. We do not count repeats (in fact, <m>\{1, 2, 3, 2, 1\}</m> is exactly the same set as <m>\{1, 2, 3\}</m>). There are sets with infinite cardinality, such as <m>\N</m>, the set of rational numbers (written <m>\mathbb Q</m>), the set of even natural numbers, and the set of real numbers (<m>\mathbb R</m>). It is possible to distinguish between different infinite cardinalities, but that is beyond the scope of this text. For us, a set will either be infinite, or finite; if it is finite, the we can determine its cardinality by counting elements.
422,424c422,424
<       <index>
<         <main>union</main>
<       </index> of the two sets. Symbolically,
---
>       <idx>
>         <h>union</h>
>       </idx> of the two sets. Symbolically,
433,435c433,435
<       <index>
<         <main>intersection</main>
<       </index>. We write,
---
>       <idx>
>         <h>intersection</h>
>       </idx>. We write,
444,446c444,446
<       <index>
<         <main>complement</main>
<       </index> of <m>A</m>, and write,
---
>       <idx>
>         <h>complement</h>
>       </idx> of <m>A</m>, and write,
462,467c462,467
<       <index>
<         <main>set difference</main>
<       </index>
<       <index>
<         <main>difference, of sets</main>
<       </index>:
---
>       <idx>
>         <h>set difference</h>
>       </idx>
>       <idx>
>         <h>difference, of sets</h>
>       </idx>:
533c533
<     There is one more way to combine sets which will be useful for us: the <term>Cartesian product</term><index><main>Cartesian product</main></index>, <m>A \times B</m><notation><usage>A\times B</usage><description>the Cartesian product of <m>A</m> and <m>B</m></description></notation>. This sounds fancy but is nothing you haven't seen before. When you graph a function in calculus, you graph it in the Cartesian plane. This is the set of all ordered pairs of real numbers <m>(x,y)</m>. We can do this for <em>any</em> pair of sets, not just the real numbers with themselves.
---
>     There is one more way to combine sets which will be useful for us: the <term>Cartesian product</term><idx><h>Cartesian product</h></idx>, <m>A \times B</m><notation><usage>A\times B</usage><description>the Cartesian product of <m>A</m> and <m>B</m></description></notation>. This sounds fancy but is nothing you haven't seen before. When you graph a function in calculus, you graph it in the Cartesian plane. This is the set of all ordered pairs of real numbers <m>(x,y)</m>. We can do this for <em>any</em> pair of sets, not just the real numbers with themselves.
568,570c568,570
<       <index>
<         <main>Venn diagram</main>
<       </index> There is a very nice visual tool we can use to represent operations on sets. A <term>Venn diagram</term> displays sets as intersecting circles. We can shade the region we are talking about when we carry out an operation. We can also represent cardinality of a particular set by putting the number in the corresponding region.
---
>       <idx>
>         <h>Venn diagram</h>
>       </idx> There is a very nice visual tool we can use to represent operations on sets. A <term>Venn diagram</term> displays sets as intersecting circles. We can shade the region we are talking about when we carry out an operation. We can also represent cardinality of a particular set by putting the number in the corresponding region.
575c575
<           <latex-image-code>
---
>           <latex-image>
579c579
<           </latex-image-code>
---
>           </latex-image>
585c585
<           <latex-image-code>
---
>           <latex-image>
589c589
<           </latex-image-code>
---
>           </latex-image>
598,600c598,600
<     <figure>
<       <image xml:id="two-set-cap" width="34%">
<         <latex-image-code>
---
>     <sidebyside width="34%">
>       <image xml:id="two-set-cap">
>         <latex-image>
608c608
<         </latex-image-code>
---
>         </latex-image>
610c610
<     </figure>
---
>     </sidebyside>
615,617c615,617
<     <figure>
<       <image xml:id="two-set-a-minus-b" width="34%">
<         <latex-image-code>
---
>     <sidebyside width="34%">
>       <image xml:id="two-set-a-minus-b">
>         <latex-image>
625c625
<         </latex-image-code>
---
>         </latex-image>
627c627
<     </figure>
---
>     </sidebyside>
632,634c632,634
<     <figure>
<       <image xml:id="three-set-complicated" width="26%">
<         <latex-image-code>
---
>     <sidebyside width="26%">
>       <image xml:id="three-set-complicated">
>         <latex-image>
647c647
<         </latex-image-code>
---
>         </latex-image>
649c649
<     </figure>
---
>     </sidebyside>
diff normal/sec_intro-statements.mbx clean/sec_intro-statements.mbx
20,21c20,21
<         <index><main>self reference</main><see>reference, self</see></index>
<         <index><main>reference, self</main><see>self reference</see></index>
---
>         <idx><h>self reference</h><see>reference, self</see></idx>
>         <idx><h>reference, self</h><see>self reference</see></idx>
38,40c38,40
<       A <term>statement</term><index>
<                 <main>statement</main>
<             </index> is any declarative sentence which is either true or false. A statement is
---
>       A <term>statement</term><idx>
>                 <h>statement</h>
>             </idx> is any declarative sentence which is either true or false. A statement is
118c118
<       <index><main>connectives</main></index>. For example, this is a molecular statement:
---
>       <idx><h>connectives</h></idx>. For example, this is a molecular statement:
141c141
<       <index><main>truth value</main></index> of the molecular statement (that is, whether the statement is true or false), based on the truth values of the statements being modified. It is important to realize that we do not need to know what the parts actually say, only whether those parts are true or false. So to analyze logical connectives, it is enough to consider <term>propositional variables</term> (sometimes called <em>sentential</em> variables), usually capital letters in the middle of the alphabet: <m>P, Q, R, S, \ldots</m>.
---
>       <idx><h>truth value</h></idx> of the molecular statement (that is, whether the statement is true or false), based on the truth values of the statements being modified. It is important to realize that we do not need to know what the parts actually say, only whether those parts are true or false. So to analyze logical connectives, it is enough to consider <term>propositional variables</term> (sometimes called <em>sentential</em> variables), usually capital letters in the middle of the alphabet: <m>P, Q, R, S, \ldots</m>.
159,163c159,163
<           <li> <m>P \wedge Q</m> means <m>P</m> and <m>Q</m>, called a <term>conjunction</term>. <index><main>conjunction</main></index> <index><main>connectives</main><sub>and</sub> </index><notation> <usage>\wedge</usage><description> logical <q>and</q> (conjunction)</description> </notation></li>
<           <li> <m>P \vee Q</m> means <m>P</m> or <m>Q</m>, called a <term>disjunction</term>. <index> <main>disjunction</main> </index> <index> <main>connectives</main> <sub>or</sub> </index><notation> <usage>\vee</usage><description>logical <q>or</q> (disjunction)</description> </notation></li>
<           <li> <m>P \imp Q</m> means if <m>P</m> then <m>Q</m>, called an <term>implication</term> or <term>conditional</term>. <index> <main>implication</main> </index> <index> <main>conditional</main> </index> <index> <main>connectives</main> <sub>implies</sub> </index> <index> <main>if<ellipsis/>, then<ellipsis/></main> </index></li>
<           <li> <m>P \iff Q</m> means <m>P</m> if and only if <m>Q</m>, called a <term>biconditional</term>. <index> <main>biconditional</main> </index> <index> <main>connectives</main> <sub>if and only if</sub> </index> <index> <main>if and only if</main> </index></li>
<           <li> <m>\neg P</m> means not <m>P</m>, called a <term>negation</term>. <index> <main>negation</main> </index> <index> <main>connectives</main> <sub>not</sub> </index><notation> <usage>\neg</usage><description>logical negation</description> </notation></li> </ul>
---
>           <li> <m>P \wedge Q</m> means <m>P</m> and <m>Q</m>, called a <term>conjunction</term>. <idx><h>conjunction</h></idx> <idx><h>connectives</h><h>and</h> </idx><notation> <usage>\wedge</usage><description> logical <q>and</q> (conjunction)</description> </notation></li>
>           <li> <m>P \vee Q</m> means <m>P</m> or <m>Q</m>, called a <term>disjunction</term>. <idx> <h>disjunction</h> </idx> <idx> <h>connectives</h> <h>or</h> </idx><notation> <usage>\vee</usage><description>logical <q>or</q> (disjunction)</description> </notation></li>
>           <li> <m>P \imp Q</m> means if <m>P</m> then <m>Q</m>, called an <term>implication</term> or <term>conditional</term>. <idx> <h>implication</h> </idx> <idx> <h>conditional</h> </idx> <idx> <h>connectives</h> <h>implies</h> </idx> <idx> <h>if<ellipsis/>, then<ellipsis/></h> </idx></li>
>           <li> <m>P \iff Q</m> means <m>P</m> if and only if <m>Q</m>, called a <term>biconditional</term>. <idx> <h>biconditional</h> </idx> <idx> <h>connectives</h> <h>if and only if</h> </idx> <idx> <h>if and only if</h> </idx></li>
>           <li> <m>\neg P</m> means not <m>P</m>, called a <term>negation</term>. <idx> <h>negation</h> </idx> <idx> <h>connectives</h> <h>not</h> </idx><notation> <usage>\neg</usage><description>logical negation</description> </notation></li> </ul>
186c186
<       Note that for us, <em>or</em> is the <term>inclusive or</term> <index> <main>inclusive or</main> </index> (and not the sometimes used <em>exclusive or</em>) meaning that <m>P \vee Q</m> is in fact true when both <m>P</m> and <m>Q</m> are true. As for the other connectives, <q>and</q> behaves as you would expect, as does negation. The biconditional (if and only if) might seem a little strange, but you should think of this as saying the two parts of the statements are <em>equivalent</em>. This leaves only the conditional <m>P \imp Q</m> which has a slightly different meaning in mathematics than it does in ordinary usage. However, implications are so common and useful in mathematics, that we must develop fluency with their use, and as such, they deserve their own subsection.
---
>       Note that for us, <em>or</em> is the <term>inclusive or</term> <idx> <h>inclusive or</h> </idx> (and not the sometimes used <em>exclusive or</em>) meaning that <m>P \vee Q</m> is in fact true when both <m>P</m> and <m>Q</m> are true. As for the other connectives, <q>and</q> behaves as you would expect, as does negation. The biconditional (if and only if) might seem a little strange, but you should think of this as saying the two parts of the statements are <em>equivalent</em>. This leaves only the conditional <m>P \imp Q</m> which has a slightly different meaning in mathematics than it does in ordinary usage. However, implications are so common and useful in mathematics, that we must develop fluency with their use, and as such, they deserve their own subsection.
209c209
<         <index>antecedent</index><index>consequent</index><index>hypothesis</index><index>conclusion</index>
---
>         <idx>antecedent</idx><idx>consequent</idx><idx>hypothesis</idx><idx>conclusion</idx>
360,362c360,362
<               <index>
<                                     <main>converse</main>
<                                 </index> of an implication
---
>               <idx>
>                                     <h>converse</h>
>                                 </idx> of an implication
373,375c373,375
<               <index>
<                                     <main>contrapositive</main>
<                                 </index> of an implication
---
>               <idx>
>                                     <h>contrapositive</h>
>                                 </idx> of an implication
565c565
<         <index> <main>necessary condition</main> </index> <index> <main>sufficient condition</main> </index>
---
>         <idx> <h>necessary condition</h> </idx> <idx> <h>sufficient condition</h> </idx>
661,663c661,663
<         <index>
<                         <main>quantifiers</main>
<                     </index>
---
>         <idx>
>                         <h>quantifiers</h>
>                     </idx>
670,676c670,676
<         <q>there is.</q> For example,<index>
<                         <main>existential quantifier</main>
<                     </index>
<         <index>
<                         <main>quantifiers</main>
<                         <sub>exists</sub>
<                     </index><notation> <usage>\exists</usage>  <description>existential quantifier </description></notation>
---
>         <q>there is.</q> For example,<idx>
>                         <h>existential quantifier</h>
>                     </idx>
>         <idx>
>                         <h>quantifiers</h>
>                         <h>exists</h>
>                     </idx><notation> <usage>\exists</usage>  <description>existential quantifier </description></notation>
687,693c687,693
<         <q>every.</q> For example,<index>
<                         <main>universal quantifier</main>
<                     </index>
<         <index>
<                         <main>quantifiers</main>
<                         <sub>for all</sub>
<                     </index>
---
>         <q>every.</q> For example,<idx>
>                         <h>universal quantifier</h>
>                     </idx>
>         <idx>
>                         <h>quantifiers</h>
>                         <h>for all</h>
>                     </idx>
diff normal/sec_logic-conc.mbx clean/sec_logic-conc.mbx
23c23
<       This is not to say that writing proofs is always straight forward. Consider again the <em>Goldbach conjecture</em>:<index><main>Goldbach conjecture</main></index>
---
>       This is not to say that writing proofs is always straight forward. Consider again the <em>Goldbach conjecture</em>:<idx><h>Goldbach conjecture</h></idx>
diff normal/sec_logic-proofs.mbx clean/sec_logic-proofs.mbx
90c90
<           There are infinitely many primes.<index><main>prime numbers</main></index>
---
>           There are infinitely many primes.<idx><h>prime numbers</h></idx>
184c184
<       <index><main>direct proof</main></index>
---
>       <idx><h>direct proof</h></idx>
254c254
<       <index><main>contrapositive</main><sub>proof by</sub></index><index><main>proof by contrapositive</main></index>
---
>       <idx><h>contrapositive</h><h>proof by</h></idx><idx><h>proof by contrapositive</h></idx>
362c362
<       <index><main>contradiction</main></index><index><main>proof by contradiction</main></index>
---
>       <idx><h>contradiction</h></idx><idx><h>proof by contradiction</h></idx>
426c426
<           The Pigeonhole Principle<index><main>Pigeonhole principle</main></index>: If more than <m>n</m> pigeons fly into <m>n</m> pigeon holes, then at least one pigeon hole will contain at least two pigeons. Prove this!
---
>           The Pigeonhole Principle<idx><h>Pigeonhole principle</h></idx>: If more than <m>n</m> pigeons fly into <m>n</m> pigeon holes, then at least one pigeon hole will contain at least two pigeons. Prove this!
446c446
<       <index><main>counterexample</main></index>
---
>       <idx><h>counterexample</h></idx>
460c460
<     <table>
---
>     <sidebyside>
483c483
<     </table>
---
>     </sidebyside>
534c534
<       <index><main>cases</main></index><index><main>proof by cases</main></index>
---
>       <idx><h>cases</h></idx><idx><h>proof by cases</h></idx>
diff normal/sec_logic-prop.mbx clean/sec_logic-prop.mbx
21c21
<     A <term>proposition</term><index><main>proposition</main></index> is simply a statement. <term>Propositional logic</term> studies the ways statements can interact with each other. It is important to remember that propositional logic does not really care about the content of the statements. For example, in terms of propositional logic, the claims, <q>if the moon is made of cheese then basketballs are round,</q> and <q>if spiders have eight legs then Sam walks with a limp</q> are exactly the same. They are both implications: statements of the form, <m>P \imp Q</m>.
---
>     A <term>proposition</term><idx><h>proposition</h></idx> is simply a statement. <term>Propositional logic</term> studies the ways statements can interact with each other. It is important to remember that propositional logic does not really care about the content of the statements. For example, in terms of propositional logic, the claims, <q>if the moon is made of cheese then basketballs are round,</q> and <q>if spiders have eight legs then Sam walks with a limp</q> are exactly the same. They are both implications: statements of the form, <m>P \imp Q</m>.
31c31
<     <index><main>truth table</main></index>
---
>     <idx><h>truth table</h></idx>
176c176
<     <table>
---
>     <sidebyside>
196c196
<     </table>
---
>     </sidebyside>
210c210
<         <table>
---
>         <sidebyside>
247c247
<         </table>
---
>         </sidebyside>
271c271
<         <table>
---
>         <sidebyside>
352c352
<         </table>
---
>         </sidebyside>
363c363
<       The statement about monopoly is an example of a <term>tautology</term><index><main>tautology</main></index>, a statement which is true on the basis of its logical form alone. Tautologies are always true but they don't tell us much about the world. No knowledge about monopoly was required to determine that the statement was true. In fact, it is equally true that <q>If the moon is made of cheese, then Elvis is still alive, or if Elvis is still alive, then unicorns have 5 legs.</q>
---
>       The statement about monopoly is an example of a <term>tautology</term><idx><h>tautology</h></idx>, a statement which is true on the basis of its logical form alone. Tautologies are always true but they don't tell us much about the world. No knowledge about monopoly was required to determine that the statement was true. In fact, it is equally true that <q>If the moon is made of cheese, then Elvis is still alive, or if Elvis is still alive, then unicorns have 5 legs.</q>
374c374
<       <table>
---
>       <sidebyside>
411c411
<       </table>
---
>       </sidebyside>
417c417
<         Two (molecular) statements <m>P</m> and <m>Q</m> are <term>logically equivalent</term> <index><main>logical equivalence</main></index> provided <m>P</m> is true precisely when <m>Q</m> is true.  That is, <m>P</m> and <m>Q</m> have the same truth value under any assignment of truth values to their atomic parts.
---
>         Two (molecular) statements <m>P</m> and <m>Q</m> are <term>logically equivalent</term> <idx><h>logical equivalence</h></idx> provided <m>P</m> is true precisely when <m>Q</m> is true.  That is, <m>P</m> and <m>Q</m> have the same truth value under any assignment of truth values to their atomic parts.
434c434
<           <table>
---
>           <sidebyside>
471c471
<           </table>
---
>           </sidebyside>
482c482
<         <index><main>De Morgan's laws</main></index>
---
>         <idx><h>De Morgan's laws</h></idx>
497c497
<         <index><main>double negation</main></index>
---
>         <idx><h>double negation</h></idx>
555c555
<         <table>
---
>         <sidebyside>
637c637
<         </table>
---
>         </sidebyside>
670c670
<     <table>
---
>     <sidebyside>
685c685
<     </table>
---
>     </sidebyside>
687,688c687,688
<       This is an example of a <term>deduction rule</term><index><main>deduction rule</main></index>, an argument form which is always valid. This one is a particularly famous rule called
<       <foreign>modus ponens</foreign><index><em>modus ponens</em></index>. Are you convinced that it is a valid deduction rule? If not, consider the following truth table:
---
>       This is an example of a <term>deduction rule</term><idx><h>deduction rule</h></idx>, an argument form which is always valid. This one is a particularly famous rule called
>       <foreign>modus ponens</foreign><idx><em>modus ponens</em></idx>. Are you convinced that it is a valid deduction rule? If not, consider the following truth table:
690c690
<     <table>
---
>     <sidebyside>
721c721
<     </table>
---
>     </sidebyside>
734c734
<         <table>
---
>         <sidebyside>
749c749
<         </table>
---
>         </sidebyside>
758c758
<         <table>
---
>         <sidebyside>
801c801
<         </table>
---
>         </sidebyside>
820c820
<         <table>
---
>         <sidebyside>
839c839
<         </table>
---
>         </sidebyside>
848c848
<         <table>
---
>         <sidebyside>
938c938
<         </table>
---
>         </sidebyside>
946c946
<           <table>
---
>           <sidebyside>
965c965
<           </table>
---
>           </sidebyside>
1036c1036
<           <table>
---
>           <sidebyside>
1047c1047
<           </table>
---
>           </sidebyside>
1055c1055
<           is always true.  This is sort of like a tautology, although we reserve that term for necessary truths in propositional logic.  A statement in predicate logic that is necessarily true gets the more prestigious designation of a <term>law of logic</term><index>law of logic</index> (or sometimes <term>logically valid</term><index><main>logically valid</main><see>law of logic</see></index>, but that is less fun).
---
>           is always true.  This is sort of like a tautology, although we reserve that term for necessary truths in propositional logic.  A statement in predicate logic that is necessarily true gets the more prestigious designation of a <term>law of logic</term><idx>law of logic</idx> (or sometimes <term>logically valid</term><idx><h>logically valid</h><see>law of logic</see></idx>, but that is less fun).
diff normal/sec_seq-arithgeom.mbx clean/sec_seq-arithgeom.mbx
14,16c14,16
<       <figure>
<       <image xml:id="inv_dots-seq1" width="65%">
<         <latex-image-code>
---
>       <sidebyside width="65%">
>       <image xml:id="inv_dots-seq1">
>         <latex-image>
27c27
<         </latex-image-code>
---
>         </latex-image>
30c30
<     </figure>
---
>     </sidebyside>
33,35c33,35
<       <figure>
<       <image xml:id="inv_dots-seq2" width="65%">
<         <latex-image-code>
---
>       <sidebyside width="65%">
>       <image xml:id="inv_dots-seq2">
>         <latex-image>
51c51
<         </latex-image-code>
---
>         </latex-image>
53c53
<     </figure>
---
>     </sidebyside>
56,58c56,58
<       <figure>
<       <image xml:id="inv_dots-seq3" width="90%">
<         <latex-image-code>
---
>       <sidebyside width="90%">
>       <image xml:id="inv_dots-seq3">
>         <latex-image>
72c72
<         </latex-image-code>
---
>         </latex-image>
74c74
<     </figure>
---
>     </sidebyside>
86c86
<         If the terms of a sequence differ by a constant, we say the sequence is <term>arithmetic</term><index><main>arithmetic sequence</main></index>.
---
>         If the terms of a sequence differ by a constant, we say the sequence is <term>arithmetic</term><idx><h>arithmetic sequence</h></idx>.
163c163
<         A sequence is called <term>geometric</term><index><main>geometric sequence</main></index> if the ratio between successive terms is constant. Suppose the initial term <m>a_0</m> is <m>a</m> and the <term>common ratio</term> is <m>r</m>. Then we have,
---
>         A sequence is called <term>geometric</term><idx><h>geometric sequence</h></idx> if the ratio between successive terms is constant. Suppose the initial term <m>a_0</m> is <m>a</m> and the <term>common ratio</term> is <m>r</m>. Then we have,
253c253
<         Look at the sequence <m>(T_n)_{n\ge 1}</m> which starts <m>1, 3, 6, 10, 15,\ldots</m>. These are called the <term>triangular numbers</term><index><main>triangular numbers</main></index> since they represent the number of dots in an equilateral triangle (think of how you arrange 10 bowling pins: a row of 4 plus a row of 3 plus a row of 2 and a row of 1).
---
>         Look at the sequence <m>(T_n)_{n\ge 1}</m> which starts <m>1, 3, 6, 10, 15,\ldots</m>. These are called the <term>triangular numbers</term><idx><h>triangular numbers</h></idx> since they represent the number of dots in an equilateral triangle (think of how you arrange 10 bowling pins: a row of 4 plus a row of 3 plus a row of 2 and a row of 1).
256,258c256,258
<       <figure>
<         <image width="50%">
<           <latex-image-code>
---
>       <sidebyside width="50%">
>         <image>
>           <latex-image>
272c272
<           </latex-image-code>
---
>           </latex-image>
275c275
<       </figure>
---
>       </sidebyside>
283c283
<         Notice that the differences between terms form an arithmetic sequence: <m>2, 3, 4, 5, 6,\ldots</m>. This says that the <m>n</m>th term of the sequence <m>1,3,6,10,15,\ldots</m> is the <em>sum</em> of the first <m>n</m> terms in the sequence <m>1,2,3,4,5,\ldots</m>. We say that the first sequence is the <term>sequence of partial sums</term><index><main>partial sums</main></index> of the second sequence (partial sums because we are not taking the sum of all infinitely many terms). If we know how to add up the terms of an arithmetic sequence, we could use this to find a closed formula for a sequence whose differences are the terms of that arithmetic sequence.
---
>         Notice that the differences between terms form an arithmetic sequence: <m>2, 3, 4, 5, 6,\ldots</m>. This says that the <m>n</m>th term of the sequence <m>1,3,6,10,15,\ldots</m> is the <em>sum</em> of the first <m>n</m> terms in the sequence <m>1,2,3,4,5,\ldots</m>. We say that the first sequence is the <term>sequence of partial sums</term><idx><h>partial sums</h></idx> of the second sequence (partial sums because we are not taking the sum of all infinitely many terms). If we know how to add up the terms of an arithmetic sequence, we could use this to find a closed formula for a sequence whose differences are the terms of that arithmetic sequence.
327c327
<           <table>
---
>           <sidebyside>
367c367
<         </table>
---
>         </sidebyside>
399c399
<           <table>
---
>           <sidebyside>
433c433
<           </table>
---
>           </sidebyside>
467c467
<             <table>
---
>             <sidebyside>
501c501
<             </table>
---
>             </sidebyside>
537c537
<       <table>
---
>       <sidebyside>
559c559
<       </table>
---
>       </sidebyside>
573c573
<           <table>
---
>           <sidebyside>
589c589
<           </table>
---
>           </sidebyside>
608c608
<           <table>
---
>           <sidebyside>
627c627
<           </table>
---
>           </sidebyside>
639c639
<         To simplify writing out sums, we will use notation like <m>\d\sum_{k=1}^n a_k</m>. This means add up the <m>a_k</m>'s where <m>k</m> changes from 1 to <m>n</m>.<index><main>summation notation</main></index><index><main>Sigma notation</main></index>
---
>         To simplify writing out sums, we will use notation like <m>\d\sum_{k=1}^n a_k</m>. This means add up the <m>a_k</m>'s where <m>k</m> changes from 1 to <m>n</m>.<idx><h>summation notation</h></idx><idx><h>Sigma notation</h></idx>
662c662
<         If we want to multiply the <m>a_k</m> instead, we would write <m>\d\prod_{k=1}^n a_k</m>. For example, <m>\d\prod_{k=1}^n k = n!</m>.<index><main>product notation</main></index>
---
>         If we want to multiply the <m>a_k</m> instead, we would write <m>\d\prod_{k=1}^n a_k</m>. For example, <m>\d\prod_{k=1}^n k = n!</m>.<idx><h>product notation</h></idx>
diff normal/sec_seq-basics.mbx clean/sec_seq-basics.mbx
14c14
<     A <term>sequence</term><index><main>sequence</main></index> is simply an ordered list of numbers. For example, here is a sequence: 0, 1, 2, 3, 4, 5, <ellipsis/>. This is different from the set <m>\N</m> because, while the sequence is a complete list of every element in the set of natural numbers, in the sequence we very much care what order the numbers come in. For this reason, when we use variables to represent terms in a sequence they will look like this:
---
>     A <term>sequence</term><idx><h>sequence</h></idx> is simply an ordered list of numbers. For example, here is a sequence: 0, 1, 2, 3, 4, 5, <ellipsis/>. This is different from the set <m>\N</m> because, while the sequence is a complete list of every element in the set of natural numbers, in the sequence we very much care what order the numbers come in. For this reason, when we use variables to represent terms in a sequence they will look like this:
106c106
<       A <term>closed formula</term><index><main>closed formula</main></index> for a sequence <m>(a_n)_{n\in\N}</m> is a formula for <m>a_n</m> using a fixed finite number of operations on <m>n</m>. This is what you normally think of as a formula in <m>n</m>, just like if you were defining a function in terms of <m>n</m> (because that is exactly what you are doing).
---
>       A <term>closed formula</term><idx><h>closed formula</h></idx> for a sequence <m>(a_n)_{n\in\N}</m> is a formula for <m>a_n</m> using a fixed finite number of operations on <m>n</m>. This is what you normally think of as a formula in <m>n</m>, just like if you were defining a function in terms of <m>n</m> (because that is exactly what you are doing).
113c113
<       A <term>recursive definition</term><index><main>recursive definition</main></index> (sometimes called an <term>inductive definition</term>) for a sequence <m>(a_n)_{n\in\N}</m> consists of a <term>recurrence relation</term><index><main>recurrence relation</main></index>: an equation relating a term of the sequence to previous terms (terms with smaller index) and an <term>initial condition</term>: a list of a few terms of the sequence (one less than the number of terms in the recurrence relation).
---
>       A <term>recursive definition</term><idx><h>recursive definition</h></idx> (sometimes called an <term>inductive definition</term>) for a sequence <m>(a_n)_{n\in\N}</m> consists of a <term>recurrence relation</term><idx><h>recurrence relation</h></idx>: an equation relating a term of the sequence to previous terms (terms with smaller index) and an <term>initial condition</term>: a list of a few terms of the sequence (one less than the number of terms in the recurrence relation).
144c144
<         In these cases, if you are given <m>n</m>, you cannot calculate <m>a_n</m> directly, you first need to find <m>a_{n-1}</m> (or <m>a_{n-1}</m> and <m>a_{n-2}</m>). In the second sequence, to find <m>a_3</m> you would take <m>2a_2</m>, but to find <m>a_2 = 2a_1</m> we would need to know <m>a_1 = 2a_0</m>.  We do know this, so we could trace back through these equations to find <m>a_1 = 54</m>, <m>a_2 = 108</m> and finally <m>a_3 = 216</m>.<index><main>Fibonacci sequence</main></index>
---
>         In these cases, if you are given <m>n</m>, you cannot calculate <m>a_n</m> directly, you first need to find <m>a_{n-1}</m> (or <m>a_{n-1}</m> and <m>a_{n-2}</m>). In the second sequence, to find <m>a_3</m> you would take <m>2a_2</m>, but to find <m>a_2 = 2a_1</m> we would need to know <m>a_1 = 2a_0</m>.  We do know this, so we could trace back through these equations to find <m>a_1 = 54</m>, <m>a_2 = 108</m> and finally <m>a_3 = 216</m>.<idx><h>Fibonacci sequence</h></idx>
289c289
<         The first few terms of <m>(T_n)_{n\ge 0}</m><notation><usage>T_n</usage><description>the <m>n</m>th triangular number</description></notation> are <m>0, 1, 3, 6, 10, 15, 21, \ldots</m> (these are called the <term>triangular numbers</term>)<index><main>triangular numbers</main></index>. The first few terms of <m>(a_n)_{n\ge 0}</m> are <m>1, 2, 4, 8, 16, \ldots</m>.  Let's try to find formulas for the given sequences:
---
>         The first few terms of <m>(T_n)_{n\ge 0}</m><notation><usage>T_n</usage><description>the <m>n</m>th triangular number</description></notation> are <m>0, 1, 3, 6, 10, 15, 21, \ldots</m> (these are called the <term>triangular numbers</term>)<idx><h>triangular numbers</h></idx>. The first few terms of <m>(a_n)_{n\ge 0}</m> are <m>1, 2, 4, 8, 16, \ldots</m>.  Let's try to find formulas for the given sequences:
diff normal/sec_seq-induction.mbx clean/sec_seq-induction.mbx
8c8
<       <index><main>induction</main></index> Mathematical induction is a proof technique, not unlike direct proof or proof by contradiction or combinatorial proof.<fn>You might or might not be familiar with these yet.  We will consider these in <xref ref="ch_logic"/>.</fn> In other words, induction is a style of argument we use to convince ourselves and others that a mathematical statement is always true. Many mathematical statements can be proved by simply explaining what they mean. Others are very difficult to prove<mdash/>in fact, there are relatively simple mathematical statements which nobody yet knows how to prove. To facilitate the discovery of proofs, it is important to be familiar with some standard styles of arguments. Induction is one such style. Let's start with an example:
---
>       <idx><h>induction</h></idx> Mathematical induction is a proof technique, not unlike direct proof or proof by contradiction or combinatorial proof.<fn>You might or might not be familiar with these yet.  We will consider these in <xref ref="ch_logic"/>.</fn> In other words, induction is a style of argument we use to convince ourselves and others that a mathematical statement is always true. Many mathematical statements can be proved by simply explaining what they mean. Others are very difficult to prove<mdash/>in fact, there are relatively simple mathematical statements which nobody yet knows how to prove. To facilitate the discovery of proofs, it is important to be familiar with some standard styles of arguments. Induction is one such style. Let's start with an example:
111c111
<         <index><main>induction</main></index> Start by saying what the statement is that you want to prove: <q>Let <m>P(n)</m> be the statement<ellipsis/></q> To prove that <m>P(n)</m> is true for all <m>n \ge 0</m>, you must prove two facts:
---
>         <idx><h>induction</h></idx> Start by saying what the statement is that you want to prove: <q>Let <m>P(n)</m> be the statement<ellipsis/></q> To prove that <m>P(n)</m> is true for all <m>n \ge 0</m>, you must prove two facts:
122c122
<               <ellipsis/> statement, so you can assume <m>P(k)</m> is true (<m>P(k)</m> is called the <em>inductive hypothesis</em><index><main>inductive hypothesis</main></index>). You must then explain why <m>P(k+1)</m> is also true, given that assumption.
---
>               <ellipsis/> statement, so you can assume <m>P(k)</m> is true (<m>P(k)</m> is called the <em>inductive hypothesis</em><idx><h>inductive hypothesis</h></idx>). You must then explain why <m>P(k+1)</m> is also true, given that assumption.
331c331
<         Still you might start to believe that you can prove anything with induction. Consider this incorrect <q>proof</q> that every Canadian<index><main>Canadians</main></index> has the same eye color: Let <m>P(n)</m> be the statement that any <m>n</m> Canadians have the same eye color. <m>P(1)</m> is true, since everyone has the same eye color as themselves. Now assume <m>P(k)</m> is true. That is, assume that in any group of <m>k</m> Canadians, everyone has the same eye color. Now consider an arbitrary group of <m>k+1</m> Canadians. The first <m>k</m> of these must all have the same eye color, since <m>P(k)</m> is true. Also, the last <m>k</m> of these must have the same eye color, since <m>P(k)</m> is true. So in fact, everyone the group must have the same eye color. Thus <m>P(k+1)</m> is true. So by the principle of mathematical induction, <m>P(n)</m> is true for all <m>n</m>.
---
>         Still you might start to believe that you can prove anything with induction. Consider this incorrect <q>proof</q> that every Canadian<idx><h>Canadians</h></idx> has the same eye color: Let <m>P(n)</m> be the statement that any <m>n</m> Canadians have the same eye color. <m>P(1)</m> is true, since everyone has the same eye color as themselves. Now assume <m>P(k)</m> is true. That is, assume that in any group of <m>k</m> Canadians, everyone has the same eye color. Now consider an arbitrary group of <m>k+1</m> Canadians. The first <m>k</m> of these must all have the same eye color, since <m>P(k)</m> is true. Also, the last <m>k</m> of these must have the same eye color, since <m>P(k)</m> is true. So in fact, everyone the group must have the same eye color. Thus <m>P(k+1)</m> is true. So by the principle of mathematical induction, <m>P(n)</m> is true for all <m>n</m>.
404c404
<       <index><main>induction</main><sub>strong induction</sub></index>
---
>       <idx><h>induction</h><h>strong induction</h></idx>
455c455
<           Prove that any natural number greater than 1 is either prime<index><main>prime numbers</main></index> or can be written as the product of primes.
---
>           Prove that any natural number greater than 1 is either prime<idx><h>prime numbers</h></idx> or can be written as the product of primes.
diff normal/sec_seq-polyfit.mbx clean/sec_seq-polyfit.mbx
5c5
<     <index><main>polynomial fitting</main></index>
---
>     <idx><h>polynomial fitting</h></idx>
35c35
<     which <em>is</em> an arithmetic sequence (with constant difference 2). Notice that our original sequence had <term>third differences</term> (that is, differences of differences of differences of the original) constant. We will call such a sequence <m>\Delta^3</m>-constant. The sequence <m>1, 4, 9, 16, \ldots</m> has second differences constant, so it will be a <m>\Delta^2</m>-constant sequence. In general, we will say a sequence is a <term><m>\Delta^k</m>-constant</term><notation><usage>\Delta^k</usage><description>the <m>k</m>th differences of a sequence</description></notation><index><main><m>\Delta^k</m>-constant</main></index> sequence if the <m>k</m>th differences are constant.
---
>     which <em>is</em> an arithmetic sequence (with constant difference 2). Notice that our original sequence had <term>third differences</term> (that is, differences of differences of differences of the original) constant. We will call such a sequence <m>\Delta^3</m>-constant. The sequence <m>1, 4, 9, 16, \ldots</m> has second differences constant, so it will be a <m>\Delta^2</m>-constant sequence. In general, we will say a sequence is a <term><m>\Delta^k</m>-constant</term><notation><usage>\Delta^k</usage><description>the <m>k</m>th differences of a sequence</description></notation><idx><h><m>\Delta^k</m>-constant</h></idx> sequence if the <m>k</m>th differences are constant.
74c74
<       <index><main>finite differences</main></index> The closed formula for a sequence will be a degree <m>k</m> polynomial if and only if the sequence is <m>\Delta^k</m>-constant (i.e., the <m>k</m>th sequence of differences is constant).
---
>       <idx><h>finite differences</h></idx> The closed formula for a sequence will be a degree <m>k</m> polynomial if and only if the sequence is <m>\Delta^k</m>-constant (i.e., the <m>k</m>th sequence of differences is constant).
179c179
<               This is the Fibonacci sequence<index><main>Fibonacci sequence</main></index>. The sequence of first differences is <m>0, 1, 1, 2, 3, 5, 8, \ldots</m>, the second differences are <m>1, 0, 1, 1, 2, 3, 5\ldots</m>. We notice that after the first few terms, we get the original sequence back. So there will never be constant differences, so the closed formula for the Fibonacci sequence is not a polynomial.
---
>               This is the Fibonacci sequence<idx><h>Fibonacci sequence</h></idx>. The sequence of first differences is <m>0, 1, 1, 2, 3, 5, 8, \ldots</m>, the second differences are <m>1, 0, 1, 1, 2, 3, 5\ldots</m>. We notice that after the first few terms, we get the original sequence back. So there will never be constant differences, so the closed formula for the Fibonacci sequence is not a polynomial.
diff normal/sec_seq-recurrence.mbx clean/sec_seq-recurrence.mbx
38c38
<       <term>solving a recurrence relation</term>. Recall that the recurrence relation is a recursive definition without the initial conditions. For example, the recurrence relation for the Fibonacci sequence<index><main>Fibonacci sequence</main></index> is <m>F_n = F_{n-1} + F_{n-2}</m>. (This, together with the initial conditions <m>F_0 = 0</m> and <m>F_1 = 1</m> give the entire recursive <em>definition</em> for the sequence.)
---
>       <term>solving a recurrence relation</term>. Recall that the recurrence relation is a recursive definition without the initial conditions. For example, the recurrence relation for the Fibonacci sequence<idx><h>Fibonacci sequence</h></idx> is <m>F_n = F_{n-1} + F_{n-2}</m>. (This, together with the initial conditions <m>F_0 = 0</m> and <m>F_1 = 1</m> give the entire recursive <em>definition</em> for the sequence.)
86c86
<       <term>Telescoping</term><index><main>telescoping</main></index> refers to the phenomenon when many terms in a large sum cancel out - so the sum <q>telescopes.</q> For example:
---
>       <term>Telescoping</term><idx><h>telescoping</h></idx> refers to the phenomenon when many terms in a large sum cancel out - so the sum <q>telescopes.</q> For example:
147c147
<       We have already seen an example of iteration when we found the closed formula for arithmetic and geometric sequences. The idea is, we <em>iterate</em><index><main>iteration</main></index> the process of finding the next term, starting with the known initial condition, up until we have <m>a_n</m>. Then we simplify. In the arithmetic sequence example, we simplified by multiplying <m>d</m> by the number of times we add it to <m>a</m> when we get to <m>a_n</m>, to get from <m>a_n = a + d + d + d + \cdots + d</m> to <m>a_n = a + dn</m>.
---
>       We have already seen an example of iteration when we found the closed formula for arithmetic and geometric sequences. The idea is, we <em>iterate</em><idx><h>iteration</h></idx> the process of finding the next term, starting with the known initial condition, up until we have <m>a_n</m>. Then we simplify. In the arithmetic sequence example, we simplified by multiplying <m>d</m> by the number of times we add it to <m>a</m> when we get to <m>a_n</m>, to get from <m>a_n = a + d + d + d + \cdots + d</m> to <m>a_n = a + dn</m>.
246c246
<     <index><main>characteristic roots</main></index>
---
>     <idx><h>characteristic roots</h></idx>
270c270
<       <term>characteristic equation</term><index><main>characteristic equation</main></index> for the recurrence relation. We are interested in finding the roots of the characteristic equation, which are called (surprise) the
---
>       <term>characteristic equation</term><idx><h>characteristic equation</h></idx> for the recurrence relation. We are interested in finding the roots of the characteristic equation, which are called (surprise) the
276c276
<         <index><main>characteristic roots</main></index> Given a recurrence relation <m>a_n + \alpha a_{n-1} + \beta a_{n-2} = 0</m>, the
---
>         <idx><h>characteristic roots</h></idx> Given a recurrence relation <m>a_n + \alpha a_{n-1} + \beta a_{n-2} = 0</m>, the
336c336
<       Perhaps the most famous recurrence relation is <m>F_n = F_{n-1} + F_{n-2}</m>, which together with the initial conditions <m>F_0 = 0</m> and <m>F_1= 1</m> defines the Fibonacci sequence<index><main>Fibonacci sequence</main></index>. But notice that this is precisely the type of recurrence relation on which we can use the characteristic root technique. When you do, the only thing that changes is that the characteristic equation does not factor, so you need to use the quadratic formula to find the characteristic roots. In fact, doing so gives the third most famous irrational number, <m>\varphi</m>, the <term>golden ratio</term>.
---
>       Perhaps the most famous recurrence relation is <m>F_n = F_{n-1} + F_{n-2}</m>, which together with the initial conditions <m>F_0 = 0</m> and <m>F_1= 1</m> defines the Fibonacci sequence<idx><h>Fibonacci sequence</h></idx>. But notice that this is precisely the type of recurrence relation on which we can use the characteristic root technique. When you do, the only thing that changes is that the characteristic equation does not factor, so you need to use the quadratic formula to find the characteristic roots. In fact, doing so gives the third most famous irrational number, <m>\varphi</m>, the <term>golden ratio</term>.
